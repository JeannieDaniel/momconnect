{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning cross-lingual embedding with Skip-gram Negative Sampling Word Embeddings\n",
    "\n",
    "Author: Jeanne Elizabeth Daniel\n",
    "\n",
    "November 2019\n",
    "\n",
    "Skip-gram negative sampling is one of the two variants of the popular Word2Vec model proposed by Mikolov et al., (2013). The skip-gram and continous bag-of-words (CBOW) is conceptually similar to the neural network language model (NNLM) proposed by Bengio et al., (2003), except it omits the hidden layer of the NNLM. \n",
    "\n",
    "The key difference between the skip-gram model and the CBOW model is that CBOW aims to predict the center word given the surrounding words, while skip-gram aims to predict the words surrounding the center word. The vector representations of words can be extracted from the projection layer and used for various down-stream tasks, such as sentiment classification.\n",
    "\n",
    "To encourage the model to learn a cross-lingual embedding space, we train it on a corpus of multilingual questions found in the MomConnect training set. Previous examinations of these questions estimated the prevalence of code-switching to be about 10%. We construct a massive multilingual vocabulary from all the words found in the training set. \n",
    "\n",
    "After training the embedding models on the questions found in the training set, we extract the cross-lingual word embeddings. We construct a sentence embedding by taking the average of all the word embeddings in the sentence (Wieting et al., 2015). Then we train $k$-nearest neighbour classifiers to predict the most appropriate answer, with $k = 1, 5, 25, 50$. The best validation scores were achieved by using cosine as the distance metric and using weighted majority voting, where the contribution of each nearest neighbour is inversely proportion to its distance from the query vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset_7B', delimiter = ';', engine = 'python')\n",
    "data = data[['helpdesk_question', 'helpdesk_reply', 'set', 'low_resource']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = pd.DataFrame(data.loc[data['set'] == 'Train']['helpdesk_reply'].value_counts()).reset_index()\n",
    "responses['reply'] = responses['index']\n",
    "responses['index'] = responses.index\n",
    "responses = dict(responses.set_index('reply')['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word2vec(data, skip_gram = 1, size = 100):\n",
    "    \n",
    "    \"\"\" Create word2vec embedding model. Word2Vec has two variants - CBOW and SGNS.  \n",
    "    \n",
    "    Args:\n",
    "        data: dataframe that contains the questions \n",
    "        skip_gram: binary indicator to use either skip-gram negative sampling or \n",
    "            continuous bag-of-words (Mikolov et al., 2013)\n",
    "        size: number of dimensions in embedding\n",
    "    \n",
    "    Returns:\n",
    "        Trained embedding model\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    documents = data['helpdesk_question']\n",
    "    documents['index'] = documents.index\n",
    "    processed_docs = documents.apply(preprocess_data.preprocess, args = [0, False])\n",
    "    print(len(processed_docs))\n",
    "    model = Word2Vec(processed_docs, min_count = 1, sg = skip_gram, seed= 1, size = size,\n",
    "                     negative = 5, ns_exponent =  0.75, workers = 5)  \n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentence_embeddings(embedding_model, sentence):\n",
    "    \n",
    "    \"\"\" We create sentence embeddings by averaging the embeddings of the words found in the sentence. \n",
    "    If no words match, we return a vector of random values.\n",
    "    \n",
    "    Args:\n",
    "        embedding_model:\n",
    "        sentence: list of words found in sentence\n",
    "        \n",
    "    Returns:\n",
    "        A sentence embedding\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    sentence_vector = np.zeros(100)\n",
    "    length = 0\n",
    "    if len(sentence) == 0:\n",
    "        return (np.random.random(100) - 0.5)/100\n",
    "    \n",
    "    if embedding_model.wv.vocab.get(sentence[0]) != None:\n",
    "        sentence_vector = embedding_model.wv[sentence[0]]\n",
    "        length += 1\n",
    "    \n",
    "    for word in sentence[1:]:\n",
    "        if embedding_model.wv.vocab.get(word) != None:\n",
    "            sentence_vector = sentence_vector + 1*np.array(embedding_model.wv[word])\n",
    "            length += 1\n",
    "            \n",
    "    if length == 0:\n",
    "        return (np.random.random(100) - 0.5)/100\n",
    "   \n",
    "    return sentence_vector/length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(df, embedding_model, D): \n",
    "        \n",
    "    \"\"\" Create batch of feature vectors in matrix form\n",
    "    \n",
    "    Args:\n",
    "        df: dataset of questions\n",
    "        embedding_model: pretrained embedding model\n",
    "        D: size of embedding\n",
    "        \n",
    "    Returns:\n",
    "        matrix where rows are embeddings of questions\n",
    "    \n",
    "    \"\"\"    \n",
    "    \n",
    "    matrix = np.zeros((df.shape[0], D, ))\n",
    "    all_text = list(df['helpdesk_question'].apply(preprocess_data.preprocess)) \n",
    "\n",
    "    for i in range(len(all_text) -1):\n",
    "        sentence_vector = create_sentence_embeddings(embedding_model, all_text[i])\n",
    "        matrix[i] += np.array(sentence_vector)\n",
    "            \n",
    "    return matrix \n",
    "\n",
    "def label_preprocess(entry):\n",
    "        \n",
    "    \"\"\" Returns integer ID corresponding to response for easy comparison and classification\n",
    "    \n",
    "    Args:\n",
    "        entry: query item \n",
    "        responses: dict containing all the template responses with their corresponding IDs\n",
    "        \n",
    "    Return: \n",
    "        integer corresponding to each response     \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    if responses.get(entry) != None:\n",
    "        return responses[entry]\n",
    "    else:\n",
    "        return len(responses) #default unknown class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df   = data.loc[data['set'] == 'Train']\n",
    "valid_df   = data.loc[data['set'] == 'Valid']\n",
    "test_df    = data.loc[data['set'] == 'Test']\n",
    "test_LR_df = data.loc[(data['set'] == 'Test') & (data['low_resource'] == 'True')]\n",
    "\n",
    "y_train   = data.loc[data['set'] == 'Train']['helpdesk_reply'].apply(label_preprocess)\n",
    "y_valid   = data.loc[data['set'] == 'Valid']['helpdesk_reply'].apply(label_preprocess)\n",
    "y_test    = data.loc[data['set'] == 'Test']['helpdesk_reply'].apply(label_preprocess)\n",
    "y_test_LR = data.loc[(data['set'] == 'Test') & (data['low_resource'] == 'True')]['helpdesk_reply'].apply(label_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeanne/.virtualenvs/tensorflow2.0-venv/lib/python3.6/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/home/jeanne/.virtualenvs/tensorflow2.0-venv/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96413\n"
     ]
    }
   ],
   "source": [
    "w2v = create_word2vec(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def train_knn_model(x_train, y_train, metric, k, weights):\n",
    "    \n",
    "    \"\"\" Fit k-nearest neighbour model to the sentence embeddings\n",
    "    \n",
    "    Args:\n",
    "        x_train: matrix of sentence embeddings\n",
    "        y_train: class labels associated with each sentence embedding \n",
    "        metric: distance metric to use\n",
    "        k: number of neighbours to consider\n",
    "        weights: to either use uniform voting (equal weighting) or weighted voting (the weight of \n",
    "        each vote is proportional to its distance to query)\n",
    "        \n",
    "    Returns:\n",
    "        A trained KNN classifier\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    clf = KNeighborsClassifier(n_neighbors=k, weights= weights, metric = metric)\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = create_batch(train_df, w2v, 100)\n",
    "x_valid = create_batch(valid_df, w2v, 100)\n",
    "x_test  = create_batch(test_df, w2v, 100)\n",
    "x_test_LR = create_batch(test_LR_df, w2v, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.9681471186159399\n",
      "Validation accuracy 0.48824910029729307\n"
     ]
    }
   ],
   "source": [
    "clf_1NN = train_knn_model(x_train = x_train, y_train = y_train, metric = 'cosine', \n",
    "                          k = 1, weights = 'distance')\n",
    "score = clf_1NN.score(x_train, y_train)\n",
    "print(\"Train accuracy\", score)\n",
    "score = clf_1NN.score(x_valid, y_valid)\n",
    "print(\"Validation accuracy\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy 0.5322797684243468\n"
     ]
    }
   ],
   "source": [
    "clf_5NN = train_knn_model(x_train = x_train, y_train = y_train, metric = 'cosine', \n",
    "                          k = 5, weights = 'distance')\n",
    "score = clf_5NN.score(x_valid, y_valid)\n",
    "print(\"Validation accuracy\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy 0.5714598654357691\n"
     ]
    }
   ],
   "source": [
    "clf_25NN = train_knn_model(x_train = x_train, y_train = y_train, metric = 'cosine', \n",
    "                          k = 25, weights = 'distance')\n",
    "score = clf_25NN.score(x_valid, y_valid)\n",
    "print(\"Validation accuracy\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy 0.5739007979971835\n"
     ]
    }
   ],
   "source": [
    "clf_50NN = train_knn_model(x_train = x_train, y_train = y_train, metric = 'cosine', \n",
    "                          k = 50, weights = 'distance')\n",
    "score = clf_50NN.score(x_valid, y_valid)\n",
    "print(\"Validation accuracy\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on 1-NN 0.4868612912232805\n",
      "Test accuracy on 5-NN 0.5351037756336674\n",
      "Test accuracy on 25-NN 0.5731393292588342\n",
      "Test accuracy on 50-NN 0.575373064871405\n"
     ]
    }
   ],
   "source": [
    "score = clf_1NN.score(x_test, y_test)\n",
    "print(\"Test accuracy on 1-NN\", score)\n",
    "score = clf_5NN.score(x_test, y_test)\n",
    "print(\"Test accuracy on 5-NN\", score)\n",
    "score = clf_25NN.score(x_test, y_test)\n",
    "print(\"Test accuracy on 25-NN\", score)\n",
    "score = clf_50NN.score(x_test, y_test)\n",
    "print(\"Test accuracy on 50-NN\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Test accuracy on 1-NN 0.373046875\n",
      "LR Test accuracy on 5-NN 0.4230769230769231\n",
      "LR Test accuracy on 25-NN 0.48001802884615385\n",
      "LR Test accuracy on 50-NN 0.4846754807692308\n"
     ]
    }
   ],
   "source": [
    "score = clf_1NN.score(x_test_LR, y_test_LR)\n",
    "print(\"LR Test accuracy on 1-NN\", score)\n",
    "score = clf_5NN.score(x_test_LR, y_test_LR)\n",
    "print(\"LR Test accuracy on 5-NN\", score)\n",
    "score = clf_25NN.score(x_test_LR, y_test_LR)\n",
    "print(\"LR Test accuracy on 25-NN\", score)\n",
    "score = clf_50NN.score(x_test_LR, y_test_LR)\n",
    "print(\"LR Test accuracy on 50-NN\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the quality of cross-lingual embeddings\n",
    "\n",
    "\n",
    "We design a small experiment to assess the quality of the cross-lingual embeddings for English and Zulu. The English sentences were synthesized based on frequently occurring questions found in the dataset. The Zulu translations were obtained using google translate and verified by a Zulu speaker. We compute the sentence embedding for each English-Zulu translation pair and calculate the cosine distance between the two embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_A  = \"can you drink coca cola when you are pregnant\"\n",
    "zulu_A = \"ungayiphuza yini i-coca cola uma ukhulelwe\"\n",
    "\n",
    "eng_B  = \"when can i stop breastfeeding\"\n",
    "zulu_B = \"ngingakuyeka nini ukuncelisa ibele\"\n",
    "\n",
    "eng_C  = \"when can I start feeding my baby solid food\"\n",
    "zulu_C = \"ngingaqala nini ukondla ingane yami ukudla okuqinile\"\n",
    "\n",
    "eng_D  = \"what are the signs of labour\"\n",
    "zulu_D = \"yiziphi izimpawu zokubeletha\"\n",
    "\n",
    "eng_E  = \"when can I learn the gender of my baby\"\n",
    "zulu_E = \"ngingabazi ubulili bengane yami\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.43539676,  0.14723022, -0.09262004,  0.25502288,  0.11587235,\n",
       "        0.06259349,  0.38609362,  0.21637774, -0.21829106,  0.64426017,\n",
       "       -0.20095043, -0.18074936,  0.07898352, -0.01266432,  0.63484   ,\n",
       "        0.17975637, -0.02500954, -0.4267427 ,  0.04626761,  0.31362945,\n",
       "        0.7310216 , -0.04467263, -0.45416588,  0.31655535,  0.4234427 ,\n",
       "       -0.15194374, -0.17476863,  0.31114313, -0.24059613, -0.11271609,\n",
       "        0.23048925,  0.19298944,  0.19004875,  0.13038677,  0.07424899,\n",
       "        0.16243826, -0.4898702 , -0.33368504, -0.4785539 ,  0.12046936,\n",
       "       -0.5566835 ,  0.37200242,  0.03245384, -0.64333767,  0.37079924,\n",
       "        0.2541796 ,  0.02759663,  0.16897526, -0.97489905, -0.02927784,\n",
       "        0.00379283,  0.6215036 , -0.2587112 , -0.02903298,  0.63286567,\n",
       "       -0.0719777 ,  0.80922073,  0.00908484,  0.38366628, -0.3711188 ,\n",
       "       -0.3862779 ,  0.33875817, -0.5076158 , -0.5550014 , -0.6456312 ,\n",
       "        0.02900601,  0.96982616,  0.6402915 ,  0.0903128 , -0.25614452,\n",
       "        0.37492976,  0.4553859 , -0.8317551 ,  0.32960013, -0.44877407,\n",
       "       -0.5832295 , -0.05401527,  0.5602947 ,  0.38924754, -0.2365005 ,\n",
       "       -0.7466143 ,  0.24193907,  0.10048347, -0.12590319,  0.09022775,\n",
       "       -0.27635106,  0.06018369,  0.964127  , -0.7267391 , -0.88670605,\n",
       "       -0.12780172, -0.4260673 , -0.35305926,  0.39580536,  0.13139261,\n",
       "        0.30970454,  0.16460507, -0.4072765 ,  0.3165753 ,  0.2235009 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_sentence_embeddings(w2v, preprocess_data.preprocess(eng_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_eng_A = create_sentence_embeddings(w2v, preprocess_data.preprocess(eng_A))\n",
    "embed_eng_B = create_sentence_embeddings(w2v, preprocess_data.preprocess(eng_B))\n",
    "embed_eng_C = create_sentence_embeddings(w2v, preprocess_data.preprocess(eng_C))\n",
    "embed_eng_D = create_sentence_embeddings(w2v, preprocess_data.preprocess(eng_D))\n",
    "embed_eng_E = create_sentence_embeddings(w2v, preprocess_data.preprocess(eng_E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_zulu_A = create_sentence_embeddings(w2v, preprocess_data.preprocess(zulu_A))\n",
    "embed_zulu_B = create_sentence_embeddings(w2v, preprocess_data.preprocess(zulu_B))\n",
    "embed_zulu_C = create_sentence_embeddings(w2v, preprocess_data.preprocess(zulu_C))\n",
    "embed_zulu_D = create_sentence_embeddings(w2v, preprocess_data.preprocess(zulu_D))\n",
    "embed_zulu_E = create_sentence_embeddings(w2v, preprocess_data.preprocess(zulu_E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence A: 0.39793431758880615\n",
      "Sentence B: 0.5983215216141248\n",
      "Sentence C: 0.5964771807193756\n",
      "Sentence D: 0.5928864777088165\n",
      "Sentence E: 0.6021465587010766\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence A:\", cosine(embed_eng_A, embed_zulu_A))\n",
    "print(\"Sentence B:\", cosine(embed_eng_B, embed_zulu_B))\n",
    "print(\"Sentence C:\", cosine(embed_eng_C, embed_zulu_C))\n",
    "print(\"Sentence D:\", cosine(embed_eng_D, embed_zulu_D))\n",
    "print(\"Sentence E:\", cosine(embed_eng_E, embed_zulu_E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
