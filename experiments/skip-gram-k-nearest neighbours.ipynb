{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning cross-lingual embedding with Skip-gram Negative Sampling Word Embeddings\n",
    "\n",
    "Author: Jeanne Elizabeth Daniel\n",
    "\n",
    "November 2019\n",
    "\n",
    "We construct a massive multilingual vocabulary from all the words found in the training set. \n",
    "\n",
    "After training the embedding models on the questions found in the training set, we extract the cross-lingual word embeddings. We construct a sentence embedding by taking the average of all the word embeddings in the sentence (Wieting et al., 2015). Then we train $k$-nearest neighbour classifiers to predict the most appropriate answer, with $k = 1, 5, 25, 50$. The best validation scores were achieved by using cosine as the distance metric and using weighted majority voting, where the contribution of each nearest neighbour is inversely proportion to its distance from the query vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset_7B', delimiter = ';', engine = 'python')\n",
    "data = data[['helpdesk_question', 'helpdesk_reply', 'set', 'low_resource']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = pd.DataFrame(data.loc[data['set'] == 'Train']['helpdesk_reply'].value_counts()).reset_index()\n",
    "responses['reply'] = responses['index']\n",
    "responses['index'] = responses.index\n",
    "responses = dict(responses.set_index('reply')['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word2vec(data, skip_gram = 1, size = 100):\n",
    "    \n",
    "    \"\"\" Create word2vec embedding model. Word2Vec has two variants - CBOW and SGNS.  \n",
    "    \n",
    "    Args:\n",
    "        data: dataframe that contains the questions \n",
    "        skip_gram: binary indicator to use either skip-gram negative sampling or \n",
    "            continuous bag-of-words (Mikolov et al., 2013)\n",
    "        size: number of dimensions in embedding\n",
    "    \n",
    "    Returns:\n",
    "        Trained embedding model\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    documents = data['helpdesk_question']\n",
    "    documents['index'] = documents.index\n",
    "    processed_docs = documents.apply(preprocess_data.preprocess, args = [0, False])\n",
    "    print(len(processed_docs))\n",
    "    model = Word2Vec(processed_docs, min_count = 1, sg = skip_gram, seed= 1, size = size,\n",
    "                     negative = 5, ns_exponent =  0.75, workers = 5)  \n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentence_embeddings(embedding_model, sentence):\n",
    "    \n",
    "    \"\"\" We create sentence embeddings by averaging the embeddings of the words found in the sentence. \n",
    "    If no words match, we return a vector of random values.\n",
    "    \n",
    "    Args:\n",
    "        embedding_model:\n",
    "        sentence: list of words found in sentence\n",
    "        \n",
    "    Returns:\n",
    "        A sentence embedding\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    sentence_vector = np.zeros(100)\n",
    "    length = 0\n",
    "    if len(sentence) == 0:\n",
    "        return (np.random.random(100) - 0.5)/100\n",
    "    \n",
    "    if embedding_model.wv.vocab.get(sentence[0]) != None:\n",
    "        sentence_vector = embedding_model.wv[sentence[0]]\n",
    "        length += 1\n",
    "    \n",
    "    for word in sentence[1:]:\n",
    "        if embedding_model.wv.vocab.get(word) != None:\n",
    "            sentence_vector = sentence_vector + 1*np.array(embedding_model.wv[word])\n",
    "            length += 1\n",
    "            \n",
    "    if length == 0:\n",
    "        return (np.random.random(100) - 0.5)/100\n",
    "   \n",
    "    return sentence_vector/length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(df, embedding_model, D): \n",
    "        \n",
    "    \"\"\" Create batch of feature vectors in matrix form\n",
    "    \n",
    "    Args:\n",
    "        df: dataset of questions\n",
    "        embedding_model: pretrained embedding model\n",
    "        D: size of embedding\n",
    "        \n",
    "    Returns:\n",
    "        matrix where rows are embeddings of questions\n",
    "    \n",
    "    \"\"\"    \n",
    "    \n",
    "    matrix = np.zeros((df.shape[0], D, ))\n",
    "    all_text = list(df['helpdesk_question'].apply(preprocess_data.preprocess)) \n",
    "\n",
    "    for i in range(len(all_text) -1):\n",
    "        sentence_vector = create_sentence_embeddings(embedding_model, all_text[i])\n",
    "        matrix[i] += np.array(sentence_vector)\n",
    "            \n",
    "    return matrix \n",
    "\n",
    "def label_preprocess(entry):\n",
    "        \n",
    "    \"\"\" Returns integer ID corresponding to response for easy comparison and classification\n",
    "    \n",
    "    Args:\n",
    "        entry: query item \n",
    "        responses: dict containing all the template responses with their corresponding IDs\n",
    "        \n",
    "    Return: \n",
    "        integer corresponding to each response     \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    if responses.get(entry) != None:\n",
    "        return responses[entry]\n",
    "    else:\n",
    "        return len(responses) #default unknown class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df   = data.loc[data['set'] == 'Train']\n",
    "valid_df   = data.loc[data['set'] == 'Valid']\n",
    "test_df    = data.loc[data['set'] == 'Test']\n",
    "test_LR_df = data.loc[(data['set'] == 'Test') & (data['low_resource'] == 'True')]\n",
    "\n",
    "y_train   = data.loc[data['set'] == 'Train']['helpdesk_reply'].apply(label_preprocess)\n",
    "y_valid   = data.loc[data['set'] == 'Valid']['helpdesk_reply'].apply(label_preprocess)\n",
    "y_test    = data.loc[data['set'] == 'Test']['helpdesk_reply'].apply(label_preprocess)\n",
    "y_test_LR = data.loc[(data['set'] == 'Test') & (data['low_resource'] == 'True')]['helpdesk_reply'].apply(label_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = create_word2vec(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def train_knn_model(x_train, y_train, metric, k, weights):\n",
    "    \n",
    "    \"\"\" Fit k-nearest neighbour model to the sentence embeddings\n",
    "    \n",
    "    Args:\n",
    "        x_train: matrix of sentence embeddings\n",
    "        y_train: class labels associated with each sentence embedding \n",
    "        metric: distance metric to use\n",
    "        k: number of neighbours to consider\n",
    "        weights: to either use uniform voting (equal weighting) or weighted voting (the weight of \n",
    "        each vote is proportional to its distance to query)\n",
    "        \n",
    "    Returns:\n",
    "        A trained KNN classifier\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    clf = KNeighborsClassifier(n_neighbors=k, weights= weights, metric = metric)\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96412\n",
      "96413\n",
      "31955\n",
      "31955\n",
      "32233\n",
      "32233\n",
      "6656\n",
      "6656\n"
     ]
    }
   ],
   "source": [
    "x_train = create_batch(train_df, w2v, 100)\n",
    "x_valid = create_batch(valid_df, w2v, 100)\n",
    "x_test  = create_batch(test_df, w2v, 100)\n",
    "x_test_LR = create_batch(test_LR_df, w2v, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Nearest Neighbours\n",
      "Train accuracy 0.9680226527818114\n",
      "Validation accuracy 0.4870286340165858\n"
     ]
    }
   ],
   "source": [
    "clf_1NN = train_knn_model(x_train = x_train, y_train = y_train, metric = 'cosine', \n",
    "                          k = 1, weights = 'distance')\n",
    "score = clf_1NN.score(x_train, y_train)\n",
    "print(\"Train accuracy\", score)\n",
    "score = clf_1NN.score(x_valid, y_valid)\n",
    "print(\"Validation accuracy\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Nearest Neighbours\n",
      "Validation accuracy 0.5318103583163825\n"
     ]
    }
   ],
   "source": [
    "clf_5NN = train_knn_model(x_train = x_train, y_train = y_train, metric = 'cosine', \n",
    "                          k = 5, weights = 'distance')\n",
    "score = clf_5NN.score(x_valid, y_valid)\n",
    "print(\"Validation accuracy\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 Nearest Neighbours\n",
      "Validation accuracy 0.5711469253637929\n"
     ]
    }
   ],
   "source": [
    "clf_25NN = train_knn_model(x_train = x_train, y_train = y_train, metric = 'cosine', \n",
    "                          k = 25, weights = 'distance')\n",
    "score = clf_25NN.score(x_valid, y_valid)\n",
    "print(\"Validation accuracy\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Nearest Neighbours\n",
      "Validation accuracy 0.574526678141136\n"
     ]
    }
   ],
   "source": [
    "clf_50NN = train_knn_model(x_train = x_train, y_train = y_train, metric = 'cosine', \n",
    "                          k = 50, weights = 'distance')\n",
    "score = clf_50NN.score(x_valid, y_valid)\n",
    "print(\"Validation accuracy\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on 1-NN 0.48766791797226444\n",
      "Test accuracy on 5-NN 0.5329631123382869\n",
      "Test accuracy on 25-NN 0.5728601123072627\n",
      "Test accuracy on 50-NN 0.5742872211708497\n"
     ]
    }
   ],
   "source": [
    "score = clf_1NN.score(x_test, y_test)\n",
    "print(\"Test accuracy on 1-NN\", score)\n",
    "score = clf_5NN.score(x_test, y_test)\n",
    "print(\"Test accuracy on 5-NN\", score)\n",
    "score = clf_25NN.score(x_test, y_test)\n",
    "print(\"Test accuracy on 25-NN\", score)\n",
    "score = clf_50NN.score(x_test, y_test)\n",
    "print(\"Test accuracy on 50-NN\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Test accuracy on 1-NN 0.3701923076923077\n",
      "LR Test accuracy on 5-NN 0.4230769230769231\n",
      "LR Test accuracy on 25-NN 0.4792668269230769\n",
      "LR Test accuracy on 50-NN 0.482421875\n"
     ]
    }
   ],
   "source": [
    "score = clf_1NN.score(x_test_LR, y_test_LR)\n",
    "print(\"LR Test accuracy on 1-NN\", score)\n",
    "score = clf_5NN.score(x_test_LR, y_test_LR)\n",
    "print(\"LR Test accuracy on 5-NN\", score)\n",
    "score = clf_25NN.score(x_test_LR, y_test_LR)\n",
    "print(\"LR Test accuracy on 25-NN\", score)\n",
    "score = clf_50NN.score(x_test_LR, y_test_LR)\n",
    "print(\"LR Test accuracy on 50-NN\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the quality of cross-lingual embeddings\n",
    "\n",
    "\n",
    "We design a small experiment to assess the quality of the cross-lingual embeddings for English and Zulu. The English sentences were synthesized based on frequently occurring questions found in the dataset. The Zulu translations were obtained using google translate and verified by a Zulu speaker. We compute the sentence embedding for each English-Zulu translation pair and calculate the cosine distance between the two embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_A  = \"can you drink coca cola when you are pregnant\"\n",
    "zulu_A = \"uma ngikhulelwe ngingaphuza i-coca-cola\"\n",
    "\n",
    "eng_B  = \"when can i stop breastfeeding\"\n",
    "zulu_B = \"ngingakuyeka nini ukuncelisa ibele\"\n",
    "\n",
    "eng_C  = \"when can I start feeding my baby solid food\"\n",
    "zulu_C = \"ngingaqala nini ukondla ingane yami ukudla okuqinile\"\n",
    "\n",
    "eng_D  = \"what are the signs of labour\"\n",
    "zulu_D = \"yiziphi izimpawu zokubeletha\"\n",
    "\n",
    "eng_E  = \"when can i find out if my baby is a boy or a girl\"\n",
    "zulu_E = \"ngingathola kanjani ukuthi ingane yami umfana noma intombazane\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20364249,  0.06353891, -0.13633114, -0.2765745 , -0.21156752,\n",
       "        0.4096739 ,  0.28027058,  0.19750798,  0.46120617, -0.42735687,\n",
       "       -0.13965902,  0.23786306,  0.22086824,  0.47389963,  0.64499557,\n",
       "       -0.4814254 ,  0.01645028,  0.40576452,  0.21119314, -0.0466147 ,\n",
       "        0.3060975 , -0.7800398 ,  0.47498357, -0.5873072 , -0.5012711 ,\n",
       "        0.41716594, -0.21051793, -0.25111225, -0.44785514,  0.11893415,\n",
       "       -0.11089575,  0.68436056,  0.307312  ,  0.05488437, -0.60432065,\n",
       "       -0.8261534 ,  0.33817112,  0.17779382,  0.69285756, -0.45616245,\n",
       "       -0.51282483,  0.02924656,  0.24955279, -0.47394207,  0.7558563 ,\n",
       "       -0.17320566,  0.340093  ,  0.04293355, -0.19062154,  0.23164397,\n",
       "        0.6927828 ,  0.29991233,  0.3498487 , -0.8781517 ,  0.36495525,\n",
       "        0.1165664 ,  0.08023944, -0.15665478, -0.62748575,  0.25193146,\n",
       "        0.03222989, -0.7912734 ,  0.5291057 ,  0.6205608 ,  0.27305987,\n",
       "        0.24024275,  0.56332576,  0.7538656 , -0.34221843, -0.06012469,\n",
       "        0.19264437,  0.05696236, -0.23432273,  0.49349192,  0.2987658 ,\n",
       "       -0.06523105, -0.17563285,  0.64735603, -0.12542431, -0.50861275,\n",
       "        0.30006766, -0.31831908, -0.2256716 , -0.14024936,  0.3384377 ,\n",
       "       -0.04620507, -0.27553642, -0.3001241 , -0.27806678, -0.4060855 ,\n",
       "        0.07324769,  0.33446735, -0.28021172, -0.3315559 , -0.48070657,\n",
       "       -0.2801918 ,  0.41400164,  0.03295957, -0.67013115,  0.85551935],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_sentence_embeddings(w2v, preprocess_data.preprocess(eng_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_eng_A = create_sentence_embeddings(w2v, preprocess_data.preprocess(eng_A))\n",
    "embed_eng_B = create_sentence_embeddings(w2v, preprocess_data.preprocess(eng_B))\n",
    "embed_eng_C = create_sentence_embeddings(w2v, preprocess_data.preprocess(eng_C))\n",
    "embed_eng_D = create_sentence_embeddings(w2v, preprocess_data.preprocess(eng_D))\n",
    "embed_eng_E = create_sentence_embeddings(w2v, preprocess_data.preprocess(eng_E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_zulu_A = create_sentence_embeddings(w2v, preprocess_data.preprocess(zulu_A))\n",
    "embed_zulu_B = create_sentence_embeddings(w2v, preprocess_data.preprocess(zulu_B))\n",
    "embed_zulu_C = create_sentence_embeddings(w2v, preprocess_data.preprocess(zulu_C))\n",
    "embed_zulu_D = create_sentence_embeddings(w2v, preprocess_data.preprocess(zulu_D))\n",
    "embed_zulu_E = create_sentence_embeddings(w2v, preprocess_data.preprocess(zulu_E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence A: 0.31717658042907715\n",
      "Sentence B: 0.6085197376973056\n",
      "Sentence C: 0.5985755920410156\n",
      "Sentence D: 0.6016709804534912\n",
      "Sentence E: 0.6159537434577942\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence A:\", cosine(embed_eng_A, embed_zulu_A))\n",
    "print(\"Sentence B:\", cosine(embed_eng_B, embed_zulu_B))\n",
    "print(\"Sentence C:\", cosine(embed_eng_C, embed_zulu_C))\n",
    "print(\"Sentence D:\", cosine(embed_eng_D, embed_zulu_D))\n",
    "print(\"Sentence E:\", cosine(embed_eng_E, embed_zulu_E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
