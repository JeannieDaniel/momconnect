{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with 256 hidden units\n",
    "\n",
    "Author: Jeanne Elizabeth Daniel\n",
    "\n",
    "November 2019\n",
    "\n",
    "We employ the humble long short-term memory network with 512 hidden units to model the input sequence of words. The LSTM was introduced by Hochreiter and Schmidhuber (1997) to address the shortcomings of the original recurrent neural network (RNN). The LSTM's architecture is similar to that of the RNN, but with more parameters, such as gating units and an internal state unit that explicitly address the long-term dependency problem of the RNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "#sys.path.append(os.path.join(\\\"..\\\")) # path to source relative to current directory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess_data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, TimeDistributed, Input, Flatten, AdditiveAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset_7B', delimiter = ';', engine = 'python')\n",
    "data_text = data.loc[data['set'] == 'Train'][['helpdesk_question']]\n",
    "number_of_classes = data.loc[data['set'] == 'Train']['helpdesk_reply'].value_counts().shape[0]\n",
    "data = data[['helpdesk_question', 'helpdesk_reply', 'set', 'low_resource']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = pd.DataFrame(data.loc[data['set'] == 'Train']['helpdesk_reply'].value_counts()).reset_index()\n",
    "responses['reply'] = responses['index']\n",
    "responses['index'] = responses.index\n",
    "responses = dict(responses.set_index('reply')['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = preprocess_data.create_dictionary(data_text, 1, 0.25, 95000) #our entire vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data.loc[data['set'] == 'Train']\n",
    "df_train = df_train.reset_index()[['helpdesk_question', 'helpdesk_reply']]\n",
    "\n",
    "df_valid = data.loc[data['set'] == 'Valid']\n",
    "df_valid = df_valid.reset_index()[['helpdesk_question', 'helpdesk_reply']]\n",
    "\n",
    "df_test = data.loc[data['set'] == 'Test']\n",
    "df_test = df_test.reset_index()[['helpdesk_question', 'helpdesk_reply']]\n",
    "\n",
    "df_LR = data.loc[(data['set'] == 'Test') & (data['low_resource'] == 'True') ]\n",
    "df_LR = df_LR.reset_index()[['helpdesk_question', 'helpdesk_reply']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96412, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57545"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 30\n",
    "min_token_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id, id_to_word = preprocess_data.create_lookup_tables(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming the input sentence into a sequence of word IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96412, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x_word_ids = []\n",
    "for question in df_train['helpdesk_question'].apply(preprocess_data.preprocess_question, \n",
    "                                                    args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    train_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "train_x_word_ids = np.stack(train_x_word_ids)\n",
    "print(train_x_word_ids.shape)\n",
    "    \n",
    "val_x_word_ids = []\n",
    "for question in data['helpdesk_question'].loc[data['set'] == 'Valid'].apply(preprocess_data.preprocess_question, \n",
    "                                                                          args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    val_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "val_x_word_ids = np.stack(val_x_word_ids)\n",
    "\n",
    "test_x_word_ids = []\n",
    "for question in data['helpdesk_question'].loc[data['set'] == 'Test'].apply(preprocess_data.preprocess_question, \n",
    "                                                                          args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    test_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "    \n",
    "test_x_word_ids = np.stack(test_x_word_ids)\n",
    "\n",
    "LR_x_word_ids = []\n",
    "for question in data['helpdesk_question'].loc[(data['set'] == 'Test') & \n",
    "                                              (data['low_resource'] == 'True')].apply(preprocess_data.preprocess_question, \n",
    "                                                                          args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    LR_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "LR_x_word_ids = np.stack(LR_x_word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(reply, all_responses):\n",
    "    \n",
    "    \"\"\" Constructs a one-hot vector for replies\n",
    "    \n",
    "    Args:\n",
    "        reply: query item \n",
    "        all_responses: dict containing all the template responses with their corresponding IDs\n",
    "    \n",
    "    Return:\n",
    "        a one-hot vector where the corresponding ID of the reply is the one-hot index\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Y = np.zeros(len(all_responses), dtype = int)\n",
    "    Y[all_responses[reply]] += 1\n",
    "    return Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.array(list(df_train['helpdesk_reply'].apply(get_dummies, args = [responses])))\n",
    "valid_y = np.array(list(df_valid['helpdesk_reply'].apply(get_dummies, args = [responses])))\n",
    "test_y  = np.array(list(df_test['helpdesk_reply'].apply(get_dummies,  args = [responses])))\n",
    "LR_y    = np.array(list(df_LR['helpdesk_reply'].apply(get_dummies,         args = [responses])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_word_ids = train_x_word_ids.reshape(train_x_word_ids.shape[:-1])\n",
    "val_x_word_ids   = val_x_word_ids.reshape(val_x_word_ids.shape[:-1])\n",
    "test_x_word_ids  = test_x_word_ids.reshape(test_x_word_ids.shape[:-1])\n",
    "LR_x_word_ids    = LR_x_word_ids.reshape(LR_x_word_ids.shape[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla LSTMs using the final hidden state as sentence embedding. \n",
    "\n",
    "The network consists of an embedding layer, followed by a dropout layer, followed by an LSTM network. The final hidden LSTM state is fed to a dense classification layer.\n",
    "We train with a dropout rate of 0.25 and batch size of 32. During training we use early stopping and Adadelta as our optimization algorithm. This network has an embedding of size 300 and 256 hidden units in the LSTM network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_lstm(max_features, output_dim=100, input_length = 30, lstm_units = 128):\n",
    "    \n",
    "    \"\"\" Constructs an LSTM classifier with an embedding and dropout layer preceding the LSTM network. \n",
    "    \n",
    "    Args:\n",
    "        max_features: size of vocabulary\n",
    "        output_dim: dimension of embedding vector\n",
    "        input_length: length of input sequence\n",
    "        lstm_units: number of hidden units in LSTM\n",
    "    \n",
    "    Returns:\n",
    "        An LSTM model\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, output_dim=output_dim, input_length = input_length, mask_zero=True ))\n",
    "    model.add(Dropout(rate = 0.25))\n",
    "    model.add(LSTM(lstm_units, activation = 'tanh', return_sequences = False, input_shape = (30,), \n",
    "               dropout = 0.25, recurrent_dropout = 0.5))\n",
    "    model.add(Dense(89, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_features = len(unique_words) + 1\n",
    "\n",
    "model = vanilla_lstm(max_features, output_dim=300, input_length=30, lstm_units = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 30, 300)           17263500  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               570368    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 89)                22873     \n",
      "=================================================================\n",
      "Total params: 17,856,741\n",
      "Trainable params: 17,856,741\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', verbose=1, restore_best_weights=True, patience=20)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96412 samples, validate on 31955 samples\n",
      "Epoch 1/500\n",
      "96412/96412 [==============================] - 247s 3ms/sample - loss: 2.6063 - accuracy: 0.4131 - val_loss: 2.0982 - val_accuracy: 0.4794\n",
      "Epoch 2/500\n",
      "96412/96412 [==============================] - 247s 3ms/sample - loss: 1.9396 - accuracy: 0.5045 - val_loss: 1.7894 - val_accuracy: 0.5288\n",
      "Epoch 3/500\n",
      "96412/96412 [==============================] - 248s 3ms/sample - loss: 1.6846 - accuracy: 0.5470 - val_loss: 1.6324 - val_accuracy: 0.5534\n",
      "Epoch 4/500\n",
      "96412/96412 [==============================] - 248s 3ms/sample - loss: 1.5204 - accuracy: 0.5764 - val_loss: 1.5518 - val_accuracy: 0.5637\n",
      "Epoch 5/500\n",
      "96412/96412 [==============================] - 248s 3ms/sample - loss: 1.3987 - accuracy: 0.6010 - val_loss: 1.4931 - val_accuracy: 0.5808\n",
      "Epoch 6/500\n",
      "96412/96412 [==============================] - 248s 3ms/sample - loss: 1.3019 - accuracy: 0.6242 - val_loss: 1.4617 - val_accuracy: 0.5894\n",
      "Epoch 7/500\n",
      "96412/96412 [==============================] - 249s 3ms/sample - loss: 1.2170 - accuracy: 0.6435 - val_loss: 1.4445 - val_accuracy: 0.5935\n",
      "Epoch 8/500\n",
      "96412/96412 [==============================] - 250s 3ms/sample - loss: 1.1352 - accuracy: 0.6649 - val_loss: 1.4273 - val_accuracy: 0.5988\n",
      "Epoch 9/500\n",
      "96412/96412 [==============================] - 251s 3ms/sample - loss: 1.0620 - accuracy: 0.6830 - val_loss: 1.4327 - val_accuracy: 0.6002\n",
      "Epoch 10/500\n",
      "96412/96412 [==============================] - 250s 3ms/sample - loss: 0.9970 - accuracy: 0.7012 - val_loss: 1.4386 - val_accuracy: 0.6009\n",
      "Epoch 11/500\n",
      "96412/96412 [==============================] - 250s 3ms/sample - loss: 0.9400 - accuracy: 0.7186 - val_loss: 1.4544 - val_accuracy: 0.6037\n",
      "Epoch 12/500\n",
      "96412/96412 [==============================] - 250s 3ms/sample - loss: 0.8907 - accuracy: 0.7318 - val_loss: 1.4666 - val_accuracy: 0.6014\n",
      "Epoch 13/500\n",
      "96412/96412 [==============================] - 251s 3ms/sample - loss: 0.8429 - accuracy: 0.7470 - val_loss: 1.4800 - val_accuracy: 0.6057\n",
      "Epoch 14/500\n",
      "96412/96412 [==============================] - 250s 3ms/sample - loss: 0.8024 - accuracy: 0.7583 - val_loss: 1.5043 - val_accuracy: 0.6055\n",
      "Epoch 15/500\n",
      "96412/96412 [==============================] - 249s 3ms/sample - loss: 0.7665 - accuracy: 0.7681 - val_loss: 1.5222 - val_accuracy: 0.6036\n",
      "Epoch 16/500\n",
      "96412/96412 [==============================] - 248s 3ms/sample - loss: 0.7376 - accuracy: 0.7772 - val_loss: 1.5343 - val_accuracy: 0.6058\n",
      "Epoch 17/500\n",
      "96412/96412 [==============================] - 248s 3ms/sample - loss: 0.7088 - accuracy: 0.7860 - val_loss: 1.5530 - val_accuracy: 0.6061\n",
      "Epoch 18/500\n",
      "96412/96412 [==============================] - 248s 3ms/sample - loss: 0.6829 - accuracy: 0.7932 - val_loss: 1.5802 - val_accuracy: 0.6049\n",
      "Epoch 19/500\n",
      "96412/96412 [==============================] - 248s 3ms/sample - loss: 0.6606 - accuracy: 0.7987 - val_loss: 1.5957 - val_accuracy: 0.6033\n",
      "Epoch 20/500\n",
      "96412/96412 [==============================] - 247s 3ms/sample - loss: 0.6365 - accuracy: 0.8042 - val_loss: 1.6141 - val_accuracy: 0.6036\n",
      "Epoch 21/500\n",
      "96412/96412 [==============================] - 246s 3ms/sample - loss: 0.6217 - accuracy: 0.8097 - val_loss: 1.6377 - val_accuracy: 0.6061\n",
      "Epoch 22/500\n",
      "96412/96412 [==============================] - 245s 3ms/sample - loss: 0.6050 - accuracy: 0.8149 - val_loss: 1.6547 - val_accuracy: 0.6041\n",
      "Epoch 23/500\n",
      "96412/96412 [==============================] - 245s 3ms/sample - loss: 0.5895 - accuracy: 0.8197 - val_loss: 1.6686 - val_accuracy: 0.6033\n",
      "Epoch 24/500\n",
      "96412/96412 [==============================] - 245s 3ms/sample - loss: 0.5760 - accuracy: 0.8235 - val_loss: 1.6852 - val_accuracy: 0.6056\n",
      "Epoch 25/500\n",
      "96412/96412 [==============================] - 246s 3ms/sample - loss: 0.5631 - accuracy: 0.8258 - val_loss: 1.6990 - val_accuracy: 0.6056\n",
      "Epoch 26/500\n",
      "96412/96412 [==============================] - 245s 3ms/sample - loss: 0.5516 - accuracy: 0.8295 - val_loss: 1.7178 - val_accuracy: 0.6065\n",
      "Epoch 27/500\n",
      "96412/96412 [==============================] - 246s 3ms/sample - loss: 0.5386 - accuracy: 0.8333 - val_loss: 1.7170 - val_accuracy: 0.6041\n",
      "Epoch 28/500\n",
      "96412/96412 [==============================] - 245s 3ms/sample - loss: 0.5284 - accuracy: 0.8367 - val_loss: 1.7387 - val_accuracy: 0.6037\n",
      "Epoch 29/500\n",
      "96412/96412 [==============================] - 246s 3ms/sample - loss: 0.5193 - accuracy: 0.8392 - val_loss: 1.7581 - val_accuracy: 0.6050\n",
      "Epoch 30/500\n",
      "96412/96412 [==============================] - 245s 3ms/sample - loss: 0.5096 - accuracy: 0.8413 - val_loss: 1.7701 - val_accuracy: 0.6045\n",
      "Epoch 31/500\n",
      "96412/96412 [==============================] - 245s 3ms/sample - loss: 0.5014 - accuracy: 0.8431 - val_loss: 1.7792 - val_accuracy: 0.6017\n",
      "Epoch 32/500\n",
      "96412/96412 [==============================] - 245s 3ms/sample - loss: 0.4960 - accuracy: 0.8457 - val_loss: 1.7902 - val_accuracy: 0.6081\n",
      "Epoch 33/500\n",
      "96412/96412 [==============================] - 230s 2ms/sample - loss: 0.4847 - accuracy: 0.8480 - val_loss: 1.7978 - val_accuracy: 0.6041\n",
      "Epoch 34/500\n",
      "96412/96412 [==============================] - 209s 2ms/sample - loss: 0.4787 - accuracy: 0.8512 - val_loss: 1.8205 - val_accuracy: 0.6032\n",
      "Epoch 35/500\n",
      "96412/96412 [==============================] - 210s 2ms/sample - loss: 0.4710 - accuracy: 0.8525 - val_loss: 1.8338 - val_accuracy: 0.6024\n",
      "Epoch 36/500\n",
      "96412/96412 [==============================] - 209s 2ms/sample - loss: 0.4667 - accuracy: 0.8544 - val_loss: 1.8357 - val_accuracy: 0.6008\n",
      "Epoch 37/500\n",
      "96412/96412 [==============================] - 210s 2ms/sample - loss: 0.4607 - accuracy: 0.8562 - val_loss: 1.8624 - val_accuracy: 0.6042\n",
      "Epoch 38/500\n",
      "96412/96412 [==============================] - 211s 2ms/sample - loss: 0.4529 - accuracy: 0.8576 - val_loss: 1.8699 - val_accuracy: 0.6017\n",
      "Epoch 39/500\n",
      "96412/96412 [==============================] - 208s 2ms/sample - loss: 0.4474 - accuracy: 0.8603 - val_loss: 1.8848 - val_accuracy: 0.6011\n",
      "Epoch 40/500\n",
      "96412/96412 [==============================] - 189s 2ms/sample - loss: 0.4420 - accuracy: 0.8607 - val_loss: 1.8859 - val_accuracy: 0.6023\n",
      "Epoch 41/500\n",
      "96412/96412 [==============================] - 189s 2ms/sample - loss: 0.4365 - accuracy: 0.8627 - val_loss: 1.9066 - val_accuracy: 0.6035\n",
      "Epoch 42/500\n",
      "96412/96412 [==============================] - 189s 2ms/sample - loss: 0.4312 - accuracy: 0.8655 - val_loss: 1.9158 - val_accuracy: 0.6021\n",
      "Epoch 43/500\n",
      "96412/96412 [==============================] - 190s 2ms/sample - loss: 0.4258 - accuracy: 0.8659 - val_loss: 1.9163 - val_accuracy: 0.6026\n",
      "Epoch 44/500\n",
      "96412/96412 [==============================] - 190s 2ms/sample - loss: 0.4209 - accuracy: 0.8674 - val_loss: 1.9464 - val_accuracy: 0.6018\n",
      "Epoch 45/500\n",
      "96412/96412 [==============================] - 190s 2ms/sample - loss: 0.4162 - accuracy: 0.8692 - val_loss: 1.9407 - val_accuracy: 0.5993\n",
      "Epoch 46/500\n",
      "96412/96412 [==============================] - 190s 2ms/sample - loss: 0.4128 - accuracy: 0.8694 - val_loss: 1.9515 - val_accuracy: 0.6008\n",
      "Epoch 47/500\n",
      "96412/96412 [==============================] - 167s 2ms/sample - loss: 0.4087 - accuracy: 0.8709 - val_loss: 1.9614 - val_accuracy: 0.6016\n",
      "Epoch 48/500\n",
      "96412/96412 [==============================] - 161s 2ms/sample - loss: 0.4057 - accuracy: 0.8711 - val_loss: 1.9634 - val_accuracy: 0.6016\n",
      "Epoch 49/500\n",
      "96412/96412 [==============================] - 161s 2ms/sample - loss: 0.4020 - accuracy: 0.8715 - val_loss: 1.9741 - val_accuracy: 0.5992\n",
      "Epoch 50/500\n",
      "96412/96412 [==============================] - 161s 2ms/sample - loss: 0.3969 - accuracy: 0.8740 - val_loss: 1.9852 - val_accuracy: 0.6028\n",
      "Epoch 51/500\n",
      "96412/96412 [==============================] - 160s 2ms/sample - loss: 0.3906 - accuracy: 0.8760 - val_loss: 1.9884 - val_accuracy: 0.6010\n",
      "Epoch 52/500\n",
      "96352/96412 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8774Restoring model weights from the end of the best epoch.\n",
      "96412/96412 [==============================] - 161s 2ms/sample - loss: 0.3888 - accuracy: 0.8773 - val_loss: 2.0104 - val_accuracy: 0.6035\n",
      "Epoch 00052: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efe968af2b0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x_word_ids, train_y,\n",
    "          batch_size=32,\n",
    "          epochs=500,\n",
    "          callbacks=[es],\n",
    "          validation_data=[val_x_word_ids, valid_y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.608166\n",
       "False    0.391834\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict_classes(test_x_word_ids)\n",
    "pd.Series(np.argmax(test_y, axis = 1) == preds).value_counts()/test_y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.52479\n",
       "False    0.47521\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict_classes(LR_x_word_ids)\n",
    "pd.Series(np.argmax(LR_y, axis = 1) == preds).value_counts()/LR_y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_score_top_5(word_ids, y_true, model):\n",
    "    \n",
    "    \"\"\" Computes top-5 classification accuracy for model.\n",
    "    \n",
    "    Args:\n",
    "        word_ids: matrix where each row is \n",
    "        y_true:\n",
    "        model:\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    score = 0\n",
    "    probs = model.predict(word_ids)\n",
    "    for i in range(word_ids.shape[0]):\n",
    "        if y_true[i].argmax() in np.argsort(probs[i])[-5:]:\n",
    "            score += 1\n",
    "        \n",
    "    print(\"Overall Accuracy:\", score/word_ids.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.8903297862439116\n"
     ]
    }
   ],
   "source": [
    "classifier_score_top_5(test_x_word_ids, test_y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.7941706730769231\n"
     ]
    }
   ],
   "source": [
    "classifier_score_top_5(LR_x_word_ids, LR_y, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
