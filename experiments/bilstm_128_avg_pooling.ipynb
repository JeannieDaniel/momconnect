{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-directional LSTM with average pooling \n",
    "\n",
    "Author: Jeanne Elizabeth Daniel\n",
    "\n",
    "November 2019\n",
    "\n",
    "We make use of a bi-directional LSTM networks that extends the modelling capabilities of the vanilla LSTM. This approach is similar to that of InferSent (Conneau et al. 2017) where the authors combine bi-directional LSTM models with pooling layers to produce high-quality sentence embeddings. In addition to InferSent, we attach a dense classification layer after the pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "#sys.path.append(os.path.join(\\\"..\\\")) # path to source relative to current directory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess_data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, TimeDistributed, Input, Flatten, AdditiveAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset_7B', delimiter = ';', engine = 'python')\n",
    "data_text = data.loc[data['set'] == 'Train'][['helpdesk_question']]\n",
    "number_of_classes = data.loc[data['set'] == 'Train']['helpdesk_reply'].value_counts().shape[0]\n",
    "data = data[['helpdesk_question', 'helpdesk_reply', 'set', 'low_resource']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = pd.DataFrame(data.loc[data['set'] == 'Train']['helpdesk_reply'].value_counts()).reset_index()\n",
    "responses['reply'] = responses['index']\n",
    "responses['index'] = responses.index\n",
    "responses = dict(responses.set_index('reply')['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = preprocess_data.create_dictionary(data_text, 1, 0.25, 95000) #our entire vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data.loc[data['set'] == 'Train']\n",
    "df_train = df_train.reset_index()[['helpdesk_question', 'helpdesk_reply']]\n",
    "\n",
    "df_valid = data.loc[data['set'] == 'Valid']\n",
    "df_valid = df_valid.reset_index()[['helpdesk_question', 'helpdesk_reply']]\n",
    "\n",
    "df_test = data.loc[data['set'] == 'Test']\n",
    "df_test = df_test.reset_index()[['helpdesk_question', 'helpdesk_reply']]\n",
    "\n",
    "df_LR = data.loc[(data['set'] == 'Test') & (data['low_resource'] == 'True') ]\n",
    "df_LR = df_LR.reset_index()[['helpdesk_question', 'helpdesk_reply']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96412, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57545"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 30\n",
    "min_token_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id, id_to_word = preprocess_data.create_lookup_tables(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming the input sentence into a sequence of word IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96412, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x_word_ids = []\n",
    "for question in df_train['helpdesk_question'].apply(preprocess_data.preprocess_question, \n",
    "                                                    args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    train_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "train_x_word_ids = np.stack(train_x_word_ids)\n",
    "print(train_x_word_ids.shape)\n",
    "    \n",
    "val_x_word_ids = []\n",
    "for question in data['helpdesk_question'].loc[data['set'] == 'Valid'].apply(preprocess_data.preprocess_question, \n",
    "                                                                          args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    val_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "val_x_word_ids = np.stack(val_x_word_ids)\n",
    "\n",
    "test_x_word_ids = []\n",
    "for question in data['helpdesk_question'].loc[data['set'] == 'Test'].apply(preprocess_data.preprocess_question, \n",
    "                                                                          args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    test_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "    \n",
    "test_x_word_ids = np.stack(test_x_word_ids)\n",
    "\n",
    "LR_x_word_ids = []\n",
    "for question in data['helpdesk_question'].loc[(data['set'] == 'Test') & \n",
    "                                              (data['low_resource'] == 'True')].apply(preprocess_data.preprocess_question, \n",
    "                                                                          args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    LR_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "LR_x_word_ids = np.stack(LR_x_word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(reply, all_responses):\n",
    "    \n",
    "    \"\"\" Constructs a one-hot vector for replies\n",
    "    \n",
    "    Args:\n",
    "        reply: query item \n",
    "        all_responses: dict containing all the template responses with their corresponding IDs\n",
    "    \n",
    "    Return:\n",
    "        a one-hot vector where the corresponding ID of the reply is the one-hot index\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Y = np.zeros(len(all_responses), dtype = int)\n",
    "    Y[all_responses[reply]] += 1\n",
    "    return Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.array(list(df_train['helpdesk_reply'].apply(get_dummies, args = [responses])))\n",
    "valid_y = np.array(list(df_valid['helpdesk_reply'].apply(get_dummies, args = [responses])))\n",
    "test_y  = np.array(list(df_test['helpdesk_reply'].apply(get_dummies,  args = [responses])))\n",
    "LR_y    = np.array(list(df_LR['helpdesk_reply'].apply(get_dummies,    args = [responses])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_word_ids = train_x_word_ids.reshape(train_x_word_ids.shape[:-1])\n",
    "val_x_word_ids   = val_x_word_ids.reshape(val_x_word_ids.shape[:-1])\n",
    "test_x_word_ids  = test_x_word_ids.reshape(test_x_word_ids.shape[:-1])\n",
    "LR_x_word_ids    = LR_x_word_ids.reshape(LR_x_word_ids.shape[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform vectors where the input sentence yields a sequence of length 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_zero_vectors = np.where(train_x_word_ids.sum(axis = 1) == 0.0)[0]\n",
    "for t in range(train_zero_vectors.shape[0]):\n",
    "    train_x_word_ids[train_zero_vectors[t]][0] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_zero_vectors = np.where(train_x_word_ids.sum(axis = 1) == 0.0)[0]\n",
    "for t in range(train_zero_vectors.shape[0]):\n",
    "    train_x_word_ids[train_zero_vectors[t]][0] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bi-directional LSTM with average pooling\n",
    "\n",
    "The network consists of an embedding layer, followed by a dropout layer. This is followed by an bi-directional LSTM layer that outputs a variable-length sequence of embedding vectors. To construct a single sentence embedding from the sequence we use average pooling. The sentence embedding is then fed to a classification layer. We train with a dropout rate of 0.5 and batch size of 32. During training we use early stopping and Adadelta as our optimization algorithm. This network has an embedding of size 300 and 128 hidden units in the biLSTM network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilstm_avg_pooling_network(max_features, input_length=30, embed_dim=100, lstm_units=512):\n",
    "    \n",
    "    \"\"\" Constructs a bi-directional LSTM network with average pooling\n",
    "    \n",
    "    Args:\n",
    "        max_features: size of vocabulary\n",
    "        input_length: length of input sequence\n",
    "        embed_dim: dimension of the embedding vector\n",
    "        lstm_units: number of hidden units in biLSTM\n",
    "        \n",
    "        \n",
    "    Returns:\n",
    "        An biLSTM model\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = Input(shape=(input_length, ))\n",
    "    x = Embedding(max_features, output_dim=embed_dim, input_length=input_length, mask_zero=True)(inputs)\n",
    "    x = (Dropout(rate = 0.5))(x)\n",
    "    x = Bidirectional(LSTM(lstm_units, activation = 'tanh', return_sequences=True,\n",
    "                           dropout=0.25, recurrent_dropout=0.5))(x)\n",
    "    x = GlobalAveragePooling1D()(x)        \n",
    "    outputs = Dense(89, activation='softmax')(x)\n",
    "    return Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_features = len(unique_words) + 1\n",
    "model = bilstm_avg_pooling_network(max_features, embed_dim=300, input_length=30, lstm_units = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 30, 300)           17263500  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 30, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 30, 256)           439296    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_7 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 89)                22873     \n",
      "=================================================================\n",
      "Total params: 17,725,669\n",
      "Trainable params: 17,725,669\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', verbose=1, restore_best_weights=True, patience=10)\n",
    "model.compile(loss='categorical_crossentropy', #optimizer = 'sgd',\n",
    "              optimizer=tf.keras.optimizers.Adadelta(learning_rate=0.5, rho=0.95),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96412 samples, validate on 31955 samples\n",
      "Epoch 1/500\n",
      "96412/96412 [==============================] - 376s 4ms/sample - loss: 2.9022 - accuracy: 0.3735 - val_loss: 2.4114 - val_accuracy: 0.4421\n",
      "Epoch 2/500\n",
      "96412/96412 [==============================] - 453s 5ms/sample - loss: 2.2559 - accuracy: 0.4625 - val_loss: 2.0839 - val_accuracy: 0.4803\n",
      "Epoch 3/500\n",
      "96412/96412 [==============================] - 454s 5ms/sample - loss: 1.9975 - accuracy: 0.4980 - val_loss: 1.8890 - val_accuracy: 0.5132\n",
      "Epoch 4/500\n",
      "96412/96412 [==============================] - 453s 5ms/sample - loss: 1.8294 - accuracy: 0.5249 - val_loss: 1.7660 - val_accuracy: 0.5325\n",
      "Epoch 5/500\n",
      "96412/96412 [==============================] - 455s 5ms/sample - loss: 1.7073 - accuracy: 0.5455 - val_loss: 1.6933 - val_accuracy: 0.5454\n",
      "Epoch 6/500\n",
      "96412/96412 [==============================] - 455s 5ms/sample - loss: 1.6122 - accuracy: 0.5628 - val_loss: 1.6249 - val_accuracy: 0.5582\n",
      "Epoch 7/500\n",
      "96412/96412 [==============================] - 458s 5ms/sample - loss: 1.5356 - accuracy: 0.5759 - val_loss: 1.5862 - val_accuracy: 0.5622\n",
      "Epoch 8/500\n",
      "96412/96412 [==============================] - 453s 5ms/sample - loss: 1.4699 - accuracy: 0.5882 - val_loss: 1.5494 - val_accuracy: 0.5700\n",
      "Epoch 9/500\n",
      "96412/96412 [==============================] - 459s 5ms/sample - loss: 1.4086 - accuracy: 0.6032 - val_loss: 1.5171 - val_accuracy: 0.5802\n",
      "Epoch 10/500\n",
      "96412/96412 [==============================] - 457s 5ms/sample - loss: 1.3569 - accuracy: 0.6140 - val_loss: 1.5016 - val_accuracy: 0.5836\n",
      "Epoch 11/500\n",
      "96412/96412 [==============================] - 456s 5ms/sample - loss: 1.3121 - accuracy: 0.6248 - val_loss: 1.4824 - val_accuracy: 0.5824\n",
      "Epoch 12/500\n",
      "96412/96412 [==============================] - 455s 5ms/sample - loss: 1.2712 - accuracy: 0.6357 - val_loss: 1.4634 - val_accuracy: 0.5899\n",
      "Epoch 13/500\n",
      "96412/96412 [==============================] - 455s 5ms/sample - loss: 1.2363 - accuracy: 0.6431 - val_loss: 1.4504 - val_accuracy: 0.5934\n",
      "Epoch 14/500\n",
      "96412/96412 [==============================] - 455s 5ms/sample - loss: 1.2004 - accuracy: 0.6514 - val_loss: 1.4448 - val_accuracy: 0.5939\n",
      "Epoch 15/500\n",
      "96412/96412 [==============================] - 453s 5ms/sample - loss: 1.1652 - accuracy: 0.6613 - val_loss: 1.4392 - val_accuracy: 0.5976\n",
      "Epoch 16/500\n",
      "96412/96412 [==============================] - 456s 5ms/sample - loss: 1.1346 - accuracy: 0.6685 - val_loss: 1.4325 - val_accuracy: 0.5993\n",
      "Epoch 17/500\n",
      "96412/96412 [==============================] - 455s 5ms/sample - loss: 1.1049 - accuracy: 0.6761 - val_loss: 1.4327 - val_accuracy: 0.6004\n",
      "Epoch 18/500\n",
      "96412/96412 [==============================] - 455s 5ms/sample - loss: 1.0791 - accuracy: 0.6818 - val_loss: 1.4319 - val_accuracy: 0.6033\n",
      "Epoch 19/500\n",
      "96412/96412 [==============================] - 455s 5ms/sample - loss: 1.0513 - accuracy: 0.6900 - val_loss: 1.4273 - val_accuracy: 0.6028\n",
      "Epoch 20/500\n",
      "96412/96412 [==============================] - 456s 5ms/sample - loss: 1.0273 - accuracy: 0.6962 - val_loss: 1.4339 - val_accuracy: 0.6063\n",
      "Epoch 21/500\n",
      "96412/96412 [==============================] - 456s 5ms/sample - loss: 1.0045 - accuracy: 0.7036 - val_loss: 1.4305 - val_accuracy: 0.6059\n",
      "Epoch 22/500\n",
      "96412/96412 [==============================] - 456s 5ms/sample - loss: 0.9860 - accuracy: 0.7085 - val_loss: 1.4320 - val_accuracy: 0.6063\n",
      "Epoch 23/500\n",
      "96412/96412 [==============================] - 460s 5ms/sample - loss: 0.9642 - accuracy: 0.7154 - val_loss: 1.4332 - val_accuracy: 0.6074\n",
      "Epoch 24/500\n",
      "96412/96412 [==============================] - 458s 5ms/sample - loss: 0.9448 - accuracy: 0.7190 - val_loss: 1.4404 - val_accuracy: 0.6090\n",
      "Epoch 25/500\n",
      "96412/96412 [==============================] - 457s 5ms/sample - loss: 0.9271 - accuracy: 0.7252 - val_loss: 1.4379 - val_accuracy: 0.6055\n",
      "Epoch 26/500\n",
      "96412/96412 [==============================] - 460s 5ms/sample - loss: 0.9118 - accuracy: 0.7294 - val_loss: 1.4417 - val_accuracy: 0.6072\n",
      "Epoch 27/500\n",
      "96412/96412 [==============================] - 461s 5ms/sample - loss: 0.8973 - accuracy: 0.7327 - val_loss: 1.4416 - val_accuracy: 0.6091\n",
      "Epoch 28/500\n",
      "96412/96412 [==============================] - 461s 5ms/sample - loss: 0.8814 - accuracy: 0.7377 - val_loss: 1.4585 - val_accuracy: 0.6101\n",
      "Epoch 29/500\n",
      "96412/96412 [==============================] - 460s 5ms/sample - loss: 0.8659 - accuracy: 0.7417 - val_loss: 1.4596 - val_accuracy: 0.6099\n",
      "Epoch 30/500\n",
      "96412/96412 [==============================] - 456s 5ms/sample - loss: 0.8534 - accuracy: 0.7453 - val_loss: 1.4584 - val_accuracy: 0.6088\n",
      "Epoch 31/500\n",
      "96412/96412 [==============================] - 457s 5ms/sample - loss: 0.8396 - accuracy: 0.7498 - val_loss: 1.4612 - val_accuracy: 0.6094\n",
      "Epoch 32/500\n",
      "96412/96412 [==============================] - 457s 5ms/sample - loss: 0.8290 - accuracy: 0.7529 - val_loss: 1.4615 - val_accuracy: 0.6125\n",
      "Epoch 33/500\n",
      "96412/96412 [==============================] - 465s 5ms/sample - loss: 0.8163 - accuracy: 0.7557 - val_loss: 1.4706 - val_accuracy: 0.6114\n",
      "Epoch 34/500\n",
      "96412/96412 [==============================] - 467s 5ms/sample - loss: 0.8052 - accuracy: 0.7598 - val_loss: 1.4713 - val_accuracy: 0.6125\n",
      "Epoch 35/500\n",
      "96412/96412 [==============================] - 466s 5ms/sample - loss: 0.7928 - accuracy: 0.7630 - val_loss: 1.4818 - val_accuracy: 0.6120\n",
      "Epoch 36/500\n",
      "96412/96412 [==============================] - 467s 5ms/sample - loss: 0.7825 - accuracy: 0.7668 - val_loss: 1.4809 - val_accuracy: 0.6129\n",
      "Epoch 37/500\n",
      "96412/96412 [==============================] - 468s 5ms/sample - loss: 0.7719 - accuracy: 0.7684 - val_loss: 1.4933 - val_accuracy: 0.6138\n",
      "Epoch 38/500\n",
      "96412/96412 [==============================] - 467s 5ms/sample - loss: 0.7648 - accuracy: 0.7720 - val_loss: 1.4917 - val_accuracy: 0.6125\n",
      "Epoch 39/500\n",
      "96412/96412 [==============================] - 468s 5ms/sample - loss: 0.7585 - accuracy: 0.7724 - val_loss: 1.4994 - val_accuracy: 0.6127\n",
      "Epoch 40/500\n",
      "96412/96412 [==============================] - 423s 4ms/sample - loss: 0.7478 - accuracy: 0.7763 - val_loss: 1.5012 - val_accuracy: 0.6085\n",
      "Epoch 41/500\n",
      "96412/96412 [==============================] - 390s 4ms/sample - loss: 0.7409 - accuracy: 0.7783 - val_loss: 1.5117 - val_accuracy: 0.6109\n",
      "Epoch 42/500\n",
      "96412/96412 [==============================] - 392s 4ms/sample - loss: 0.7330 - accuracy: 0.7806 - val_loss: 1.5078 - val_accuracy: 0.6067\n",
      "Epoch 43/500\n",
      "96412/96412 [==============================] - 392s 4ms/sample - loss: 0.7224 - accuracy: 0.7826 - val_loss: 1.5234 - val_accuracy: 0.6115\n",
      "Epoch 44/500\n",
      "96412/96412 [==============================] - 395s 4ms/sample - loss: 0.7163 - accuracy: 0.7843 - val_loss: 1.5152 - val_accuracy: 0.6091\n",
      "Epoch 45/500\n",
      "96412/96412 [==============================] - 394s 4ms/sample - loss: 0.7095 - accuracy: 0.7871 - val_loss: 1.5223 - val_accuracy: 0.6142\n",
      "Epoch 46/500\n",
      "96412/96412 [==============================] - 393s 4ms/sample - loss: 0.7037 - accuracy: 0.7872 - val_loss: 1.5268 - val_accuracy: 0.6110\n",
      "Epoch 47/500\n",
      "96412/96412 [==============================] - 395s 4ms/sample - loss: 0.6976 - accuracy: 0.7904 - val_loss: 1.5385 - val_accuracy: 0.6131\n",
      "Epoch 48/500\n",
      "96412/96412 [==============================] - 393s 4ms/sample - loss: 0.6898 - accuracy: 0.7920 - val_loss: 1.5301 - val_accuracy: 0.6100\n",
      "Epoch 49/500\n",
      "96412/96412 [==============================] - 392s 4ms/sample - loss: 0.6816 - accuracy: 0.7945 - val_loss: 1.5422 - val_accuracy: 0.6138\n",
      "Epoch 50/500\n",
      "96412/96412 [==============================] - 391s 4ms/sample - loss: 0.6785 - accuracy: 0.7955 - val_loss: 1.5493 - val_accuracy: 0.6123\n",
      "Epoch 51/500\n",
      "96412/96412 [==============================] - 391s 4ms/sample - loss: 0.6732 - accuracy: 0.7970 - val_loss: 1.5505 - val_accuracy: 0.6121\n",
      "Epoch 52/500\n",
      "96412/96412 [==============================] - 391s 4ms/sample - loss: 0.6667 - accuracy: 0.7985 - val_loss: 1.5551 - val_accuracy: 0.6104\n",
      "Epoch 53/500\n",
      "96412/96412 [==============================] - 388s 4ms/sample - loss: 0.6603 - accuracy: 0.8011 - val_loss: 1.5565 - val_accuracy: 0.6102\n",
      "Epoch 54/500\n",
      "96412/96412 [==============================] - 387s 4ms/sample - loss: 0.6556 - accuracy: 0.8005 - val_loss: 1.5685 - val_accuracy: 0.6120\n",
      "Epoch 55/500\n",
      "96384/96412 [============================>.] - ETA: 0s - loss: 0.6514 - accuracy: 0.8032Restoring model weights from the end of the best epoch.\n",
      "96412/96412 [==============================] - 386s 4ms/sample - loss: 0.6515 - accuracy: 0.8031 - val_loss: 1.5678 - val_accuracy: 0.6110\n",
      "Epoch 00055: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f524d4ecef0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x_word_ids, train_y, \n",
    "          batch_size=32,\n",
    "          epochs=500,\n",
    "          callbacks=[es],\n",
    "          validation_data=[val_x_word_ids, valid_y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_score_top_1(word_ids, y_true, model):\n",
    "    \n",
    "    \"\"\" Computes top-1 classification accuracy for model.\n",
    "    \n",
    "    Args:\n",
    "        word_ids: matrix where each row is \n",
    "        y_true: true labels\n",
    "        model: trained model\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    score = 0\n",
    "    probs = model.predict(word_ids)\n",
    "    for i in range(word_ids.shape[0]):\n",
    "        if y_true[i].argmax() == np.argsort(probs[i])[-1]:\n",
    "            score += 1\n",
    "        \n",
    "    print(\"Overall Accuracy:\", score/word_ids.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.6137188595538734\n"
     ]
    }
   ],
   "source": [
    "classifier_score_top_1(test_x_word_ids, test_y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.5341045673076923\n"
     ]
    }
   ],
   "source": [
    "classifier_score_top_1(LR_x_word_ids, LR_y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-5 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_score_top_5(word_ids, y_true, model):\n",
    "    \n",
    "    \"\"\" Computes top-5 classification accuracy for model.\n",
    "    \n",
    "    Args:\n",
    "        word_ids: matrix where each row is \n",
    "        y_true: true labels\n",
    "        model: trained model\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    score = 0\n",
    "    probs = model.predict(word_ids)\n",
    "    for i in range(word_ids.shape[0]):\n",
    "        if y_true[i].argmax() in np.argsort(probs[i])[-5:]:\n",
    "            score += 1\n",
    "        \n",
    "    print(\"Overall Accuracy:\", score/word_ids.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.8999162349145285\n"
     ]
    }
   ],
   "source": [
    "classifier_score_top_5(test_x_word_ids, test_y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.8036358173076923\n"
     ]
    }
   ],
   "source": [
    "classifier_score_top_5(LR_x_word_ids, LR_y, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
