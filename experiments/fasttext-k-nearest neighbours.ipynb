{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning cross-lingual embedding with FastText Embeddings\n",
    "\n",
    "Author: Jeanne Elizabeth Daniel\n",
    "\n",
    "November 2019\n",
    "\n",
    "FastText (Bojanowskiet al., 2017) is conceptually similar to SGNS, except it also takes into account subword information. Each word is broken up into a set of character $n$-grams, with special boundary symbols at the beginning and end of each word. The original word is also retained in the set. Thus, fir $n=3$, the word \"there\" is represented by the following $n$-grams \"<th\", \"the\", \"her\", \"ere\", \"re>\" and the special token \"\\< there>\".\n",
    "\n",
    "This simple approach enables sharing representations across the vocabulary,can handle rare words better, and can even handle unseen words (a property theat SGNS models lack). We learn a cross-lingual embedding space from the multilingual questions by relying on the estimated 10% prevalence of code-mixing. \n",
    "\n",
    "After training the embedding models on the questions found in the training set, we extract the cross-lingual word embeddings. We construct a sentence embedding by taking the average of all the word embeddings in the sentence (Wieting et al., 2015). Then we train $k$-nearest neighbour classifiers to predict the most appropriate answer, with $k = 1, 5, 25, 50$. The best validation scores were achieved by using cosine as the distance metric and using weighted majority voting, where the contribution of each nearest neighbour is inversely proportion to its distance from the query vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset_7B', delimiter = ';', engine = 'python')\n",
    "data = data[['helpdesk_question', 'helpdesk_reply', 'set', 'low_resource']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = pd.DataFrame(data.loc[data['set'] == 'Train']['helpdesk_reply'].value_counts()).reset_index()\n",
    "responses['reply'] = responses['index']\n",
    "responses['index'] = responses.index\n",
    "responses = dict(responses.set_index('reply')['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fasttext(data, skip_gram= 1, min_count = 1, size = 100):\n",
    "    \n",
    "    \"\"\" Train a fasttext embedding model. \n",
    "    The FastText model implicitly creates a multilingual vocabulary from the multilingual dataset. \n",
    "    The estimate 10% code-switching is used as a weak cross-lingual signal to construct \n",
    "    cross-lingual embeddings\n",
    "    \n",
    "    Args:\n",
    "        data: dataframe that contains the questions \n",
    "        skip_gram: binary indicator to use either skip-gram negative sampling or \n",
    "            continuous bag-of-words (Mikolov et al., 2013)\n",
    "        size: number of dimensions in embedding\n",
    "        \n",
    "    Returns:\n",
    "        Trained embedding model\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    documents = data['helpdesk_question']\n",
    "    documents['index'] = documents.index\n",
    "    processed_docs = documents.apply(preprocess_data.preprocess, args = [0, False])\n",
    "    \n",
    "    model = FastText(sentences=processed_docs, sg=skip_gram, size=size, window=5, min_count=min_count, \n",
    "                     word_ngrams=1, sample=0.001, seed=1, workers=5, negative=5, ns_exponent=0.75,\n",
    "                     iter=5, min_n=3, max_n=6, trim_rule=None)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentence_embeddings(embedding_model, sentence):\n",
    "    \n",
    "    \"\"\" We create sentence embeddings by averaging the embeddings of the words found in the sentence. \n",
    "    If no words match, we return a vector of random values.\n",
    "    \n",
    "    Args:\n",
    "        embedding_model: pretrained word embedding model\n",
    "        sentence: list of words found in sentence\n",
    "        \n",
    "    Returns:\n",
    "        A sentence embedding for the input sentence\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sentence_vector = np.zeros(100)\n",
    "    length = 0\n",
    "    \n",
    "    if len(sentence) == 0:\n",
    "        return (np.random.random(100) - 0.5)/100\n",
    "    \n",
    "    if embedding_model.wv.vocab.get(sentence[0]) != None:\n",
    "        sentence_vector = embedding_model.wv[sentence[0]]\n",
    "        length += 1\n",
    "    \n",
    "    for word in sentence[1:]:\n",
    "        if embedding_model.wv.vocab.get(word) != None:\n",
    "            sentence_vector = sentence_vector + 1*np.array(embedding_model.wv[word])\n",
    "            length += 1\n",
    "            \n",
    "    if length == 0:\n",
    "        return (np.random.random(100) - 0.5)/100\n",
    "   \n",
    "    return sentence_vector/length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(df, embedding_model, D): \n",
    "        \n",
    "    \"\"\" Create batch of feature vectors in matrix form\n",
    "    \n",
    "    Args:\n",
    "        df: dataset of questions\n",
    "        embedding_model: pretrained embedding model\n",
    "        D: size of embedding\n",
    "        \n",
    "    Returns:\n",
    "        matrix where rows are embeddings of questions\n",
    "    \n",
    "    \"\"\"    \n",
    "    \n",
    "    matrix = np.zeros((df.shape[0], D, ))\n",
    "    all_text = list(df['helpdesk_question'].apply(preprocess_data.preprocess)) \n",
    "    \n",
    "    for i in range(len(all_text) -1):\n",
    "        sentence_vector = create_sentence_embeddings(embedding_model, all_text[i])\n",
    "        matrix[i] += np.array(sentence_vector)\n",
    "            \n",
    "    return matrix \n",
    "\n",
    "def label_preprocess(entry):\n",
    "    \n",
    "    \"\"\" Returns integer ID corresponding to response for easy comparison and classification\n",
    "    \n",
    "    Args:\n",
    "        entry: query item \n",
    "        responses: dict containing all the template responses with their corresponding IDs\n",
    "        \n",
    "    Return: \n",
    "        integer corresponding to each response     \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    if responses.get(entry) != None:\n",
    "        return responses[entry]\n",
    "    else:\n",
    "        return len(responses) #default unknown class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df   = data.loc[data['set'] == 'Train']\n",
    "valid_df   = data.loc[data['set'] == 'Valid']\n",
    "test_df    = data.loc[data['set'] == 'Test']\n",
    "test_LR_df = data.loc[(data['set'] == 'Test') & (data['low_resource'] == 'True')]\n",
    "\n",
    "y_train   = data.loc[data['set'] == 'Train']['helpdesk_reply'].apply(label_preprocess)\n",
    "y_valid   = data.loc[data['set'] == 'Valid']['helpdesk_reply'].apply(label_preprocess)\n",
    "y_test    = data.loc[data['set'] == 'Test']['helpdesk_reply'].apply(label_preprocess)\n",
    "y_test_LR = data.loc[(data['set'] == 'Test') & (data['low_resource'] == 'True')]['helpdesk_reply'].apply(label_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeanne/.virtualenvs/tensorflow2.0-venv/lib/python3.6/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/home/jeanne/.virtualenvs/tensorflow2.0-venv/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "fast = create_fasttext(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def train_knn_model(x_train, y_train, metric, k, weights):\n",
    "    \n",
    "    \"\"\" Fit k-nearest neighbour model to the sentence embeddings\n",
    "    \n",
    "    Args:\n",
    "        x_train: matrix of sentence embeddings\n",
    "        y_train: class labels associated with each sentence embedding \n",
    "        metric: distance metric to use\n",
    "        k: number of neighbours to consider\n",
    "        weights: to either use uniform voting (equal weighting) or weighted voting (the weight of \n",
    "        each vote is proportional to its distance to query)\n",
    "        \n",
    "    Returns:\n",
    "        A trained KNN classifier\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    clf = KNeighborsClassifier(n_neighbors=k, weights= weights, metric = metric)\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = create_batch(train_df, fast, 100)\n",
    "x_valid = create_batch(valid_df, fast, 100)\n",
    "x_test  = create_batch(test_df, fast, 100)\n",
    "x_test_LR = create_batch(test_LR_df, fast, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.9681471186159399\n",
      "Validation accuracy 0.4981380065717415\n"
     ]
    }
   ],
   "source": [
    "clf_1NN = train_knn_model(x_train = x_train, y_train = y_train, metric = 'cosine', \n",
    "                          k = 1, weights = 'distance')\n",
    "score = clf_1NN.score(x_train, y_train)\n",
    "print(\"Train accuracy\", score)\n",
    "score = clf_1NN.score(x_valid, y_valid)\n",
    "print(\"Validation accuracy\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy 0.546894069785636\n"
     ]
    }
   ],
   "source": [
    "clf_5NN = train_knn_model(x_train = x_train, y_train = y_train, metric = 'cosine', \n",
    "                          k = 5, weights = 'distance')\n",
    "score = clf_5NN.score(x_valid, y_valid)\n",
    "print(\"Validation accuracy\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy 0.5837271162572367\n"
     ]
    }
   ],
   "source": [
    "clf_25NN = train_knn_model(x_train = x_train, y_train = y_train, metric = 'cosine', \n",
    "                          k = 25, weights = 'distance')\n",
    "score = clf_25NN.score(x_valid, y_valid)\n",
    "print(\"Validation accuracy\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy 0.584040056329213\n"
     ]
    }
   ],
   "source": [
    "clf_50NN = train_knn_model(x_train = x_train, y_train = y_train, metric = 'cosine', \n",
    "                          k = 50, weights = 'distance')\n",
    "score = clf_50NN.score(x_valid, y_valid)\n",
    "print(\"Validation accuracy\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on 1-NN 0.5005118977445475\n",
      "Test accuracy on 5-NN 0.5444110073527131\n",
      "Test accuracy on 25-NN 0.5848043930133714\n",
      "Test accuracy on 50-NN 0.5839357180529271\n"
     ]
    }
   ],
   "source": [
    "score = clf_1NN.score(x_test, y_test)\n",
    "print(\"Test accuracy on 1-NN\", score)\n",
    "score = clf_5NN.score(x_test, y_test)\n",
    "print(\"Test accuracy on 5-NN\", score)\n",
    "score = clf_25NN.score(x_test, y_test)\n",
    "print(\"Test accuracy on 25-NN\", score)\n",
    "score = clf_50NN.score(x_test, y_test)\n",
    "print(\"Test accuracy on 50-NN\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Test accuracy on 1-NN 0.3942307692307692\n",
      "LR Test accuracy on 5-NN 0.4391526442307692\n",
      "LR Test accuracy on 25-NN 0.494140625\n",
      "LR Test accuracy on 50-NN 0.49759615384615385\n"
     ]
    }
   ],
   "source": [
    "score = clf_1NN.score(x_test_LR, y_test_LR)\n",
    "print(\"LR Test accuracy on 1-NN\", score)\n",
    "score = clf_5NN.score(x_test_LR, y_test_LR)\n",
    "print(\"LR Test accuracy on 5-NN\", score)\n",
    "score = clf_25NN.score(x_test_LR, y_test_LR)\n",
    "print(\"LR Test accuracy on 25-NN\", score)\n",
    "score = clf_50NN.score(x_test_LR, y_test_LR)\n",
    "print(\"LR Test accuracy on 50-NN\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the quality of cross-lingual embeddings\n",
    "\n",
    "We design a small experiment to assess the quality of the cross-lingual embeddings for English and Zulu. The translations were obtained using google translate and verified by a Zulu speaker. We compute the sentence embedding for each English-Zulu translation pair and calculate the cosine distance between the two embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_A  = \"can you drink coca cola when you are pregnant\"\n",
    "zulu_A = \"ungayiphuza yini i-coca cola uma ukhulelwe\"\n",
    "\n",
    "eng_B  = \"when can i stop breastfeeding\"\n",
    "zulu_B = \"ngingakuyeka nini ukuncelisa ibele\"\n",
    "\n",
    "eng_C  = \"when can I start feeding my baby solid food\"\n",
    "zulu_C = \"ngingaqala nini ukondla ingane yami ukudla okuqinile\"\n",
    "\n",
    "eng_D  = \"what are the signs of labour\"\n",
    "zulu_D = \"yiziphi izimpawu zokubeletha\"\n",
    "\n",
    "eng_E  = \"when can I learn the gender of my baby\"\n",
    "zulu_E = \"ngingabazi ubulili bengane yami\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_eng_A = create_sentence_embeddings(fast, preprocess_data.preprocess(eng_A))\n",
    "embed_eng_B = create_sentence_embeddings(fast, preprocess_data.preprocess(eng_B))\n",
    "embed_eng_C = create_sentence_embeddings(fast, preprocess_data.preprocess(eng_C))\n",
    "embed_eng_D = create_sentence_embeddings(fast, preprocess_data.preprocess(eng_D))\n",
    "embed_eng_E = create_sentence_embeddings(fast, preprocess_data.preprocess(eng_E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_zulu_A = create_sentence_embeddings(fast, preprocess_data.preprocess(zulu_A))\n",
    "embed_zulu_B = create_sentence_embeddings(fast, preprocess_data.preprocess(zulu_B))\n",
    "embed_zulu_C = create_sentence_embeddings(fast, preprocess_data.preprocess(zulu_C))\n",
    "embed_zulu_D = create_sentence_embeddings(fast, preprocess_data.preprocess(zulu_D))\n",
    "embed_zulu_E = create_sentence_embeddings(fast, preprocess_data.preprocess(zulu_E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence A: 0.3769022226333618\n",
      "Sentence B: 0.5876132222684076\n",
      "Sentence C: 0.5461249947547913\n",
      "Sentence D: 0.647421807050705\n",
      "Sentence E: 0.6305571736233155\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence A:\", cosine(embed_eng_A, embed_zulu_A))\n",
    "print(\"Sentence B:\", cosine(embed_eng_B, embed_zulu_B))\n",
    "print(\"Sentence C:\", cosine(embed_eng_C, embed_zulu_C))\n",
    "print(\"Sentence D:\", cosine(embed_eng_D, embed_zulu_D))\n",
    "print(\"Sentence E:\", cosine(embed_eng_E, embed_zulu_E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
