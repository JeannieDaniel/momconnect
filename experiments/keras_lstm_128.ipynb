{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with 128 hidden units\n",
    "\n",
    "Author: Jeanne Elizabeth Daniel\n",
    "\n",
    "November 2019\n",
    "\n",
    "We employ the humble long short-term memory network with 512 hidden units to model the input sequence of words. The LSTM was introduced by Hochreiter and Schmidhuber (1997) to address the shortcomings of the original recurrent neural network (RNN). The LSTM's architecture is similar to that of the RNN, but with more parameters, such as gating units and an internal state unit that explicitly address the long-term dependency problem of the RNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "#sys.path.append(os.path.join(\\\"..\\\")) # path to source relative to current directory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess_data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, TimeDistributed, Input, Flatten, AdditiveAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset_7B', delimiter = ';', engine = 'python')\n",
    "data_text = data.loc[data['set'] == 'Train'][['helpdesk_question']]\n",
    "number_of_classes = data.loc[data['set'] == 'Train']['helpdesk_reply'].value_counts().shape[0]\n",
    "data = data[['helpdesk_question', 'helpdesk_reply', 'set', 'low_resource']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = pd.DataFrame(data.loc[data['set'] == 'Train']['helpdesk_reply'].value_counts()).reset_index()\n",
    "responses['reply'] = responses['index']\n",
    "responses['index'] = responses.index\n",
    "responses = dict(responses.set_index('reply')['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = preprocess_data.create_dictionary(data_text, 1, 0.25, 95000) #our entire vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data.loc[data['set'] == 'Train']\n",
    "df_train = df_train.reset_index()[['helpdesk_question', 'helpdesk_reply']]\n",
    "\n",
    "df_valid = data.loc[data['set'] == 'Valid']\n",
    "df_valid = df_valid.reset_index()[['helpdesk_question', 'helpdesk_reply']]\n",
    "\n",
    "df_test = data.loc[data['set'] == 'Test']\n",
    "df_test = df_test.reset_index()[['helpdesk_question', 'helpdesk_reply']]\n",
    "\n",
    "df_LR = data.loc[(data['set'] == 'Test') & (data['low_resource'] == 'True') ]\n",
    "df_LR = df_LR.reset_index()[['helpdesk_question', 'helpdesk_reply']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96412, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57545"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 30\n",
    "min_token_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id, id_to_word = preprocess_data.create_lookup_tables(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming the input sentence into a sequence of word IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96412, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x_word_ids = []\n",
    "for question in df_train['helpdesk_question'].apply(preprocess_data.preprocess_question, \n",
    "                                                    args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    train_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "train_x_word_ids = np.stack(train_x_word_ids)\n",
    "print(train_x_word_ids.shape)\n",
    "    \n",
    "val_x_word_ids = []\n",
    "for question in data['helpdesk_question'].loc[data['set'] == 'Valid'].apply(preprocess_data.preprocess_question, \n",
    "                                                                          args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    val_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "val_x_word_ids = np.stack(val_x_word_ids)\n",
    "\n",
    "test_x_word_ids = []\n",
    "for question in data['helpdesk_question'].loc[data['set'] == 'Test'].apply(preprocess_data.preprocess_question, \n",
    "                                                                          args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    test_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "    \n",
    "test_x_word_ids = np.stack(test_x_word_ids)\n",
    "\n",
    "LR_x_word_ids = []\n",
    "for question in data['helpdesk_question'].loc[(data['set'] == 'Test') & \n",
    "                                              (data['low_resource'] == 'True')].apply(preprocess_data.preprocess_question, \n",
    "                                                                          args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    LR_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "LR_x_word_ids = np.stack(LR_x_word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(reply, all_responses):\n",
    "    \n",
    "    \"\"\" Constructs a one-hot vector for replies\n",
    "    \n",
    "    Args:\n",
    "        reply: query item \n",
    "        all_responses: dict containing all the template responses with their corresponding IDs\n",
    "    \n",
    "    Return:\n",
    "        a one-hot vector where the corresponding ID of the reply is the one-hot index\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Y = np.zeros(len(all_responses), dtype = int)\n",
    "    Y[all_responses[reply]] += 1\n",
    "    return Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.array(list(df_train['helpdesk_reply'].apply(get_dummies, args = [responses])))\n",
    "valid_y = np.array(list(df_valid['helpdesk_reply'].apply(get_dummies, args = [responses])))\n",
    "test_y  = np.array(list(df_test['helpdesk_reply'].apply(get_dummies,  args = [responses])))\n",
    "LR_y    = np.array(list(df_LR['helpdesk_reply'].apply(get_dummies,         args = [responses])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_word_ids = train_x_word_ids.reshape(train_x_word_ids.shape[:-1])\n",
    "val_x_word_ids   = val_x_word_ids.reshape(val_x_word_ids.shape[:-1])\n",
    "test_x_word_ids  = test_x_word_ids.reshape(test_x_word_ids.shape[:-1])\n",
    "LR_x_word_ids    = LR_x_word_ids.reshape(LR_x_word_ids.shape[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla LSTMs using the final hidden state as sentence embedding. \n",
    "\n",
    "The network consists of an embedding layer, followed by a dropout layer, followed by an LSTM network. The final hidden LSTM state is fed to a dense classification layer.\n",
    "We train with a dropout rate of 0.25 and batch size of 32. During training we use early stopping and Adadelta as our optimization algorithm. This network has an embedding of size 300 and 128 hidden units in the LSTM network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_lstm(max_features, output_dim=100, input_length = 30, lstm_units = 128):\n",
    "    \n",
    "    \"\"\" Constructs an LSTM classifier with an embedding and dropout layer preceding the LSTM network. \n",
    "    \n",
    "    Args:\n",
    "        max_features: size of vocabulary\n",
    "        output_dim: dimension of embedding vector\n",
    "        input_length: length of input sequence\n",
    "        lstm_units: number of hidden units in LSTM\n",
    "    \n",
    "    Returns:\n",
    "        An LSTM model\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, output_dim=output_dim, input_length = input_length, mask_zero=True ))\n",
    "    model.add(Dropout(rate = 0.25))\n",
    "    model.add(LSTM(lstm_units, activation = 'tanh', return_sequences = False, input_shape = (30,), \n",
    "               dropout = 0.25, recurrent_dropout = 0.5))\n",
    "    model.add(Dense(89, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_features = len(unique_words) + 1\n",
    "\n",
    "model = vanilla_lstm(max_features, output_dim=300, input_length=30, lstm_units = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 30, 300)           17263500  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 89)                11481     \n",
      "=================================================================\n",
      "Total params: 17,494,629\n",
      "Trainable params: 17,494,629\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', verbose=1, restore_best_weights=True, patience=20)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96412 samples, validate on 31955 samples\n",
      "Epoch 1/500\n",
      "96412/96412 [==============================] - 246s 3ms/sample - loss: 2.6475 - accuracy: 0.4108 - val_loss: 2.1219 - val_accuracy: 0.4762\n",
      "Epoch 2/500\n",
      "96412/96412 [==============================] - 245s 3ms/sample - loss: 1.9536 - accuracy: 0.5064 - val_loss: 1.7925 - val_accuracy: 0.5297\n",
      "Epoch 3/500\n",
      "96412/96412 [==============================] - 245s 3ms/sample - loss: 1.6828 - accuracy: 0.5473 - val_loss: 1.6405 - val_accuracy: 0.5537\n",
      "Epoch 4/500\n",
      "96412/96412 [==============================] - 247s 3ms/sample - loss: 1.5103 - accuracy: 0.5792 - val_loss: 1.5562 - val_accuracy: 0.5695\n",
      "Epoch 5/500\n",
      "96412/96412 [==============================] - 247s 3ms/sample - loss: 1.3828 - accuracy: 0.6055 - val_loss: 1.4986 - val_accuracy: 0.5805\n",
      "Epoch 6/500\n",
      "96412/96412 [==============================] - 247s 3ms/sample - loss: 1.2803 - accuracy: 0.6302 - val_loss: 1.4705 - val_accuracy: 0.5905\n",
      "Epoch 7/500\n",
      "96412/96412 [==============================] - 248s 3ms/sample - loss: 1.1866 - accuracy: 0.6509 - val_loss: 1.4538 - val_accuracy: 0.5976\n",
      "Epoch 8/500\n",
      "96412/96412 [==============================] - 250s 3ms/sample - loss: 1.1035 - accuracy: 0.6728 - val_loss: 1.4440 - val_accuracy: 0.6001\n",
      "Epoch 9/500\n",
      "96412/96412 [==============================] - 249s 3ms/sample - loss: 1.0342 - accuracy: 0.6932 - val_loss: 1.4422 - val_accuracy: 0.6019\n",
      "Epoch 10/500\n",
      "96412/96412 [==============================] - 249s 3ms/sample - loss: 0.9687 - accuracy: 0.7106 - val_loss: 1.4493 - val_accuracy: 0.6037\n",
      "Epoch 11/500\n",
      "96412/96412 [==============================] - 249s 3ms/sample - loss: 0.9101 - accuracy: 0.7270 - val_loss: 1.4691 - val_accuracy: 0.6029\n",
      "Epoch 12/500\n",
      "96412/96412 [==============================] - 250s 3ms/sample - loss: 0.8641 - accuracy: 0.7402 - val_loss: 1.4791 - val_accuracy: 0.6039\n",
      "Epoch 13/500\n",
      "96412/96412 [==============================] - 248s 3ms/sample - loss: 0.8219 - accuracy: 0.7532 - val_loss: 1.4960 - val_accuracy: 0.6032\n",
      "Epoch 14/500\n",
      "96412/96412 [==============================] - 249s 3ms/sample - loss: 0.7834 - accuracy: 0.7632 - val_loss: 1.5201 - val_accuracy: 0.6031\n",
      "Epoch 15/500\n",
      "96412/96412 [==============================] - 248s 3ms/sample - loss: 0.7534 - accuracy: 0.7731 - val_loss: 1.5327 - val_accuracy: 0.6023\n",
      "Epoch 16/500\n",
      "96412/96412 [==============================] - 247s 3ms/sample - loss: 0.7250 - accuracy: 0.7812 - val_loss: 1.5534 - val_accuracy: 0.6034\n",
      "Epoch 17/500\n",
      "96412/96412 [==============================] - 247s 3ms/sample - loss: 0.7001 - accuracy: 0.7872 - val_loss: 1.5705 - val_accuracy: 0.6021\n",
      "Epoch 18/500\n",
      "96412/96412 [==============================] - 245s 3ms/sample - loss: 0.6758 - accuracy: 0.7964 - val_loss: 1.5815 - val_accuracy: 0.6039\n",
      "Epoch 19/500\n",
      "96412/96412 [==============================] - 245s 3ms/sample - loss: 0.6584 - accuracy: 0.8001 - val_loss: 1.6048 - val_accuracy: 0.6046\n",
      "Epoch 20/500\n",
      "96412/96412 [==============================] - 244s 3ms/sample - loss: 0.6400 - accuracy: 0.8058 - val_loss: 1.6137 - val_accuracy: 0.6031\n",
      "Epoch 21/500\n",
      "96412/96412 [==============================] - 246s 3ms/sample - loss: 0.6253 - accuracy: 0.8099 - val_loss: 1.6305 - val_accuracy: 0.6006\n",
      "Epoch 22/500\n",
      "96412/96412 [==============================] - 244s 3ms/sample - loss: 0.6104 - accuracy: 0.8142 - val_loss: 1.6456 - val_accuracy: 0.6043\n",
      "Epoch 23/500\n",
      "96412/96412 [==============================] - 245s 3ms/sample - loss: 0.6001 - accuracy: 0.8162 - val_loss: 1.6585 - val_accuracy: 0.6038\n",
      "Epoch 24/500\n",
      "96412/96412 [==============================] - 243s 3ms/sample - loss: 0.5863 - accuracy: 0.8210 - val_loss: 1.6765 - val_accuracy: 0.6011\n",
      "Epoch 25/500\n",
      "96412/96412 [==============================] - 245s 3ms/sample - loss: 0.5769 - accuracy: 0.8227 - val_loss: 1.6889 - val_accuracy: 0.6009\n",
      "Epoch 26/500\n",
      "96412/96412 [==============================] - 245s 3ms/sample - loss: 0.5658 - accuracy: 0.8267 - val_loss: 1.6961 - val_accuracy: 0.6006\n",
      "Epoch 27/500\n",
      "96412/96412 [==============================] - 245s 3ms/sample - loss: 0.5553 - accuracy: 0.8291 - val_loss: 1.7146 - val_accuracy: 0.6022\n",
      "Epoch 28/500\n",
      "96412/96412 [==============================] - 245s 3ms/sample - loss: 0.5488 - accuracy: 0.8301 - val_loss: 1.7218 - val_accuracy: 0.6028\n",
      "Epoch 29/500\n",
      "96412/96412 [==============================] - 244s 3ms/sample - loss: 0.5368 - accuracy: 0.8341 - val_loss: 1.7324 - val_accuracy: 0.6028\n",
      "Epoch 30/500\n",
      "96412/96412 [==============================] - 243s 3ms/sample - loss: 0.5302 - accuracy: 0.8357 - val_loss: 1.7433 - val_accuracy: 0.6006\n",
      "Epoch 31/500\n",
      "96412/96412 [==============================] - 244s 3ms/sample - loss: 0.5244 - accuracy: 0.8389 - val_loss: 1.7589 - val_accuracy: 0.5966\n",
      "Epoch 32/500\n",
      "96412/96412 [==============================] - 245s 3ms/sample - loss: 0.5182 - accuracy: 0.8390 - val_loss: 1.7572 - val_accuracy: 0.6002\n",
      "Epoch 33/500\n",
      "96412/96412 [==============================] - 235s 2ms/sample - loss: 0.5124 - accuracy: 0.8414 - val_loss: 1.7755 - val_accuracy: 0.6023\n",
      "Epoch 34/500\n",
      "96412/96412 [==============================] - 210s 2ms/sample - loss: 0.5069 - accuracy: 0.8430 - val_loss: 1.7882 - val_accuracy: 0.6002\n",
      "Epoch 35/500\n",
      "96412/96412 [==============================] - 210s 2ms/sample - loss: 0.5011 - accuracy: 0.8446 - val_loss: 1.7854 - val_accuracy: 0.5985\n",
      "Epoch 36/500\n",
      "96412/96412 [==============================] - 209s 2ms/sample - loss: 0.4968 - accuracy: 0.8460 - val_loss: 1.7954 - val_accuracy: 0.5974\n",
      "Epoch 37/500\n",
      "96412/96412 [==============================] - 210s 2ms/sample - loss: 0.4920 - accuracy: 0.8468 - val_loss: 1.8134 - val_accuracy: 0.5976\n",
      "Epoch 38/500\n",
      "96412/96412 [==============================] - 212s 2ms/sample - loss: 0.4847 - accuracy: 0.8485 - val_loss: 1.8293 - val_accuracy: 0.5990\n",
      "Epoch 39/500\n",
      "96384/96412 [============================>.] - ETA: 0s - loss: 0.4819 - accuracy: 0.8497Restoring model weights from the end of the best epoch.\n",
      "96412/96412 [==============================] - 211s 2ms/sample - loss: 0.4820 - accuracy: 0.8497 - val_loss: 1.8290 - val_accuracy: 0.5987\n",
      "Epoch 00039: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5cdb162b38>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x_word_ids, train_y,\n",
    "          batch_size=32,\n",
    "          epochs=500,\n",
    "          callbacks=[es],\n",
    "          validation_data=[val_x_word_ids, valid_y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.604536\n",
       "False    0.395464\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict_classes(test_x_word_ids)\n",
    "pd.Series(np.argmax(test_y, axis = 1) == preds).value_counts()/test_y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.522987\n",
       "False    0.477013\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict_classes(LR_x_word_ids)\n",
    "pd.Series(np.argmax(LR_y, axis = 1) == preds).value_counts()/LR_y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_score_top_5(word_ids, y_true, model):\n",
    "    \n",
    "    \"\"\" Computes top-5 classification accuracy for model.\n",
    "    \n",
    "    Args:\n",
    "        word_ids: matrix where each row is \n",
    "        y_true:\n",
    "        model:\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    score = 0\n",
    "    probs = model.predict(word_ids)\n",
    "    for i in range(word_ids.shape[0]):\n",
    "        if y_true[i].argmax() in np.argsort(probs[i])[-5:]:\n",
    "            score += 1\n",
    "        \n",
    "    print(\"Overall Accuracy:\", score/word_ids.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.8960692458039897\n"
     ]
    }
   ],
   "source": [
    "classifier_score_top_5(test_x_word_ids, test_y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.8093449519230769\n"
     ]
    }
   ],
   "source": [
    "classifier_score_top_5(LR_x_word_ids, LR_y, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
