{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with 512 hidden units\n",
    "\n",
    "Author: Jeanne Elizabeth Daniel\n",
    "\n",
    "November 2019\n",
    "\n",
    "We employ the humble long short-term memory network with 512 hidden units to model the input sequence of words. The LSTM was introduced by Hochreiter and Schmidhuber (1997) to address the shortcomings of the original recurrent neural network (RNN). The LSTM's architecture is similar to that of the RNN, but with more parameters, such as gating units and an internal state unit that explicitly address the long-term dependency problem of the RNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "#sys.path.append(os.path.join(\\\"..\\\")) # path to source relative to current directory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, TimeDistributed, Input, Flatten, AdditiveAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess_data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset_7B', delimiter = ';', engine = 'python')\n",
    "data_text = data.loc[data['set'] == 'Train'][['helpdesk_question']]\n",
    "number_of_classes = data.loc[data['set'] == 'Train']['helpdesk_reply'].value_counts().shape[0]\n",
    "data = data[['helpdesk_question', 'helpdesk_reply', 'set', 'low_resource']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = pd.DataFrame(data.loc[data['set'] == 'Train']['helpdesk_reply'].value_counts()).reset_index()\n",
    "responses['reply'] = responses['index']\n",
    "responses['index'] = responses.index\n",
    "responses = dict(responses.set_index('reply')['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = preprocess_data.create_dictionary(data_text, 1, 0.25, 95000) #our entire vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data.loc[data['set'] == 'Train']\n",
    "df_train = df_train.reset_index()[['helpdesk_question', 'helpdesk_reply']]\n",
    "\n",
    "df_valid = data.loc[data['set'] == 'Valid']\n",
    "df_valid = df_valid.reset_index()[['helpdesk_question', 'helpdesk_reply']]\n",
    "\n",
    "df_test = data.loc[data['set'] == 'Test']\n",
    "df_test = df_test.reset_index()[['helpdesk_question', 'helpdesk_reply']]\n",
    "\n",
    "df_LR = data.loc[(data['set'] == 'Test') & (data['low_resource'] == 'True') ]\n",
    "df_LR = df_LR.reset_index()[['helpdesk_question', 'helpdesk_reply']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96412, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57545"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 30\n",
    "min_token_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id, id_to_word = preprocess_data.create_lookup_tables(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming the input sentence into a sequence of word IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96412, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x_word_ids = []\n",
    "for question in df_train['helpdesk_question'].apply(preprocess_data.preprocess_question, \n",
    "                                                    args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    train_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "train_x_word_ids = np.stack(train_x_word_ids)\n",
    "print(train_x_word_ids.shape)\n",
    "    \n",
    "val_x_word_ids = []\n",
    "for question in data['helpdesk_question'].loc[data['set'] == 'Valid'].apply(preprocess_data.preprocess_question, \n",
    "                                                                          args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    val_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "val_x_word_ids = np.stack(val_x_word_ids)\n",
    "\n",
    "test_x_word_ids = []\n",
    "for question in data['helpdesk_question'].loc[data['set'] == 'Test'].apply(preprocess_data.preprocess_question, \n",
    "                                                                          args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    test_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "    \n",
    "test_x_word_ids = np.stack(test_x_word_ids)\n",
    "\n",
    "LR_x_word_ids = []\n",
    "for question in data['helpdesk_question'].loc[(data['set'] == 'Test') & \n",
    "                                              (data['low_resource'] == 'True')].apply(preprocess_data.preprocess_question, \n",
    "                                                                          args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    LR_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "LR_x_word_ids = np.stack(LR_x_word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(reply, all_responses):\n",
    "    \n",
    "    \"\"\" Constructs a one-hot vector for replies\n",
    "    \n",
    "    Args:\n",
    "        reply: query item \n",
    "        all_responses: dict containing all the template responses with their corresponding IDs\n",
    "    \n",
    "    Return:\n",
    "        a one-hot vector where the corresponding ID of the reply is the one-hot index\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Y = np.zeros(len(all_responses), dtype = int)\n",
    "    Y[all_responses[reply]] += 1\n",
    "    return Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.array(list(df_train['helpdesk_reply'].apply(get_dummies, args = [responses])))\n",
    "valid_y = np.array(list(df_valid['helpdesk_reply'].apply(get_dummies, args = [responses])))\n",
    "test_y  = np.array(list(df_test['helpdesk_reply'].apply(get_dummies,  args = [responses])))\n",
    "LR_y    = np.array(list(df_LR['helpdesk_reply'].apply(get_dummies,         args = [responses])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_word_ids = train_x_word_ids.reshape(train_x_word_ids.shape[:-1])\n",
    "val_x_word_ids   = val_x_word_ids.reshape(val_x_word_ids.shape[:-1])\n",
    "test_x_word_ids  = test_x_word_ids.reshape(test_x_word_ids.shape[:-1])\n",
    "LR_x_word_ids    = LR_x_word_ids.reshape(LR_x_word_ids.shape[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla LSTMs using the final hidden state as sentence embedding. \n",
    "\n",
    "The network consists of an embedding layer, followed by a dropout layer, followed by an LSTM network. The final hidden LSTM state is fed to a dense classification layer.\n",
    "We train with a dropout rate of 0.25 and batch size of 32. During training we use early stopping and Adadelta as our optimization algorithm. This network has an embedding of size 300 and 512 hidden units in the LSTM network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_lstm(max_features, output_dim=100, input_length = 30, lstm_units = 128):\n",
    "    \n",
    "    \"\"\" Constructs an LSTM classifier with an embedding and dropout layer preceding the LSTM network. \n",
    "    \n",
    "    Args:\n",
    "        max_features: size of vocabulary\n",
    "        output_dim: dimension of embedding vector\n",
    "        input_length: length of input sequence\n",
    "        lstm_units: number of hidden units in LSTM\n",
    "    \n",
    "    Returns:\n",
    "        An LSTM model\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, output_dim=output_dim, input_length = input_length, mask_zero=True ))\n",
    "    model.add(Dropout(rate = 0.25))\n",
    "    model.add(LSTM(lstm_units, activation = 'tanh', return_sequences = False, input_shape = (30,), \n",
    "               dropout = 0.25, recurrent_dropout = 0.5))\n",
    "    model.add(Dense(89, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_features = len(unique_words) + 1\n",
    "\n",
    "model = vanilla_lstm(max_features, output_dim=300, input_length=30, lstm_units = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 30, 300)           17263500  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 512)               1665024   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 89)                45657     \n",
      "=================================================================\n",
      "Total params: 18,974,181\n",
      "Trainable params: 18,974,181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', verbose=1, restore_best_weights=True, patience=20)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96412 samples, validate on 31955 samples\n",
      "Epoch 1/500\n",
      "96412/96412 [==============================] - 243s 3ms/sample - loss: 2.6016 - accuracy: 0.4115 - val_loss: 2.0923 - val_accuracy: 0.4769\n",
      "Epoch 2/500\n",
      "96412/96412 [==============================] - 246s 3ms/sample - loss: 1.9537 - accuracy: 0.5006 - val_loss: 1.7959 - val_accuracy: 0.5196\n",
      "Epoch 3/500\n",
      "96412/96412 [==============================] - 247s 3ms/sample - loss: 1.7055 - accuracy: 0.5408 - val_loss: 1.6590 - val_accuracy: 0.5492\n",
      "Epoch 4/500\n",
      "96412/96412 [==============================] - 248s 3ms/sample - loss: 1.5480 - accuracy: 0.5703 - val_loss: 1.5651 - val_accuracy: 0.5659\n",
      "Epoch 5/500\n",
      "96412/96412 [==============================] - 246s 3ms/sample - loss: 1.4292 - accuracy: 0.5926 - val_loss: 1.5155 - val_accuracy: 0.5767\n",
      "Epoch 6/500\n",
      "96412/96412 [==============================] - 247s 3ms/sample - loss: 1.3320 - accuracy: 0.6141 - val_loss: 1.4795 - val_accuracy: 0.5809\n",
      "Epoch 7/500\n",
      "96412/96412 [==============================] - 247s 3ms/sample - loss: 1.2477 - accuracy: 0.6334 - val_loss: 1.4521 - val_accuracy: 0.5889\n",
      "Epoch 8/500\n",
      "96412/96412 [==============================] - 247s 3ms/sample - loss: 1.1685 - accuracy: 0.6550 - val_loss: 1.4527 - val_accuracy: 0.5915\n",
      "Epoch 9/500\n",
      "96412/96412 [==============================] - 247s 3ms/sample - loss: 1.0954 - accuracy: 0.6728 - val_loss: 1.4462 - val_accuracy: 0.5960\n",
      "Epoch 10/500\n",
      "96412/96412 [==============================] - 246s 3ms/sample - loss: 1.0297 - accuracy: 0.6919 - val_loss: 1.4515 - val_accuracy: 0.6010\n",
      "Epoch 11/500\n",
      "96412/96412 [==============================] - 245s 3ms/sample - loss: 0.9722 - accuracy: 0.7070 - val_loss: 1.4571 - val_accuracy: 0.6017\n",
      "Epoch 12/500\n",
      "96412/96412 [==============================] - 244s 3ms/sample - loss: 0.9137 - accuracy: 0.7236 - val_loss: 1.4723 - val_accuracy: 0.6011\n",
      "Epoch 13/500\n",
      "96412/96412 [==============================] - 244s 3ms/sample - loss: 0.8696 - accuracy: 0.7376 - val_loss: 1.4970 - val_accuracy: 0.6077\n",
      "Epoch 14/500\n",
      "96412/96412 [==============================] - 242s 3ms/sample - loss: 0.8248 - accuracy: 0.7503 - val_loss: 1.5040 - val_accuracy: 0.6052\n",
      "Epoch 15/500\n",
      "96412/96412 [==============================] - 243s 3ms/sample - loss: 0.7845 - accuracy: 0.7616 - val_loss: 1.5271 - val_accuracy: 0.6031\n",
      "Epoch 16/500\n",
      "96412/96412 [==============================] - 243s 3ms/sample - loss: 0.7505 - accuracy: 0.7716 - val_loss: 1.5586 - val_accuracy: 0.6051\n",
      "Epoch 17/500\n",
      "96412/96412 [==============================] - 243s 3ms/sample - loss: 0.7219 - accuracy: 0.7793 - val_loss: 1.5698 - val_accuracy: 0.6047\n",
      "Epoch 18/500\n",
      "96412/96412 [==============================] - 243s 3ms/sample - loss: 0.6920 - accuracy: 0.7885 - val_loss: 1.5913 - val_accuracy: 0.6060\n",
      "Epoch 19/500\n",
      "96412/96412 [==============================] - 243s 3ms/sample - loss: 0.6642 - accuracy: 0.7977 - val_loss: 1.6274 - val_accuracy: 0.6016\n",
      "Epoch 20/500\n",
      "96412/96412 [==============================] - 243s 3ms/sample - loss: 0.6420 - accuracy: 0.8044 - val_loss: 1.6233 - val_accuracy: 0.6052\n",
      "Epoch 21/500\n",
      "96412/96412 [==============================] - 243s 3ms/sample - loss: 0.6216 - accuracy: 0.8092 - val_loss: 1.6482 - val_accuracy: 0.6041\n",
      "Epoch 22/500\n",
      "96412/96412 [==============================] - 244s 3ms/sample - loss: 0.5995 - accuracy: 0.8146 - val_loss: 1.6562 - val_accuracy: 0.6070\n",
      "Epoch 23/500\n",
      "96412/96412 [==============================] - 243s 3ms/sample - loss: 0.5819 - accuracy: 0.8198 - val_loss: 1.6983 - val_accuracy: 0.6064\n",
      "Epoch 24/500\n",
      "96412/96412 [==============================] - 243s 3ms/sample - loss: 0.5655 - accuracy: 0.8255 - val_loss: 1.7135 - val_accuracy: 0.6013\n",
      "Epoch 25/500\n",
      "96412/96412 [==============================] - 244s 3ms/sample - loss: 0.5476 - accuracy: 0.8300 - val_loss: 1.7373 - val_accuracy: 0.6037\n",
      "Epoch 26/500\n",
      "96412/96412 [==============================] - 244s 3ms/sample - loss: 0.5329 - accuracy: 0.8352 - val_loss: 1.7450 - val_accuracy: 0.6045\n",
      "Epoch 27/500\n",
      "96412/96412 [==============================] - 244s 3ms/sample - loss: 0.5174 - accuracy: 0.8374 - val_loss: 1.7633 - val_accuracy: 0.6050\n",
      "Epoch 28/500\n",
      "96412/96412 [==============================] - 244s 3ms/sample - loss: 0.5071 - accuracy: 0.8424 - val_loss: 1.7751 - val_accuracy: 0.6029\n",
      "Epoch 29/500\n",
      "96412/96412 [==============================] - 244s 3ms/sample - loss: 0.4950 - accuracy: 0.8446 - val_loss: 1.7944 - val_accuracy: 0.6041\n",
      "Epoch 30/500\n",
      "96412/96412 [==============================] - 243s 3ms/sample - loss: 0.4823 - accuracy: 0.8487 - val_loss: 1.8171 - val_accuracy: 0.6057\n",
      "Epoch 31/500\n",
      "96412/96412 [==============================] - 243s 3ms/sample - loss: 0.4708 - accuracy: 0.8519 - val_loss: 1.8337 - val_accuracy: 0.6012\n",
      "Epoch 32/500\n",
      "96412/96412 [==============================] - 244s 3ms/sample - loss: 0.4591 - accuracy: 0.8555 - val_loss: 1.8532 - val_accuracy: 0.6009\n",
      "Epoch 33/500\n",
      "96384/96412 [============================>.] - ETA: 0s - loss: 0.4494 - accuracy: 0.8587Restoring model weights from the end of the best epoch.\n",
      "96412/96412 [==============================] - 244s 3ms/sample - loss: 0.4495 - accuracy: 0.8587 - val_loss: 1.8624 - val_accuracy: 0.6016\n",
      "Epoch 00033: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f927d2539b0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x_word_ids, train_y,\n",
    "          batch_size=32,\n",
    "          epochs=500,\n",
    "          callbacks=[es],\n",
    "          validation_data=[val_x_word_ids, valid_y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.609034\n",
       "False    0.390966\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict_classes(test_x_word_ids)\n",
    "pd.Series(np.argmax(test_y, axis = 1) == preds).value_counts()/test_y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.527344\n",
       "False    0.472656\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict_classes(LR_x_word_ids)\n",
    "pd.Series(np.argmax(LR_y, axis = 1) == preds).value_counts()/LR_y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_score_top_5(word_ids, y_true, model):\n",
    "    \n",
    "    \"\"\" Computes top-5 classification accuracy for model.\n",
    "    \n",
    "    Args:\n",
    "        word_ids: matrix where each row is \n",
    "        y_true: true labels\n",
    "        model: trained model\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    score = 0\n",
    "    probs = model.predict(word_ids)\n",
    "    for i in range(word_ids.shape[0]):\n",
    "        if y_true[i].argmax() in np.argsort(probs[i])[-5:]:\n",
    "            score += 1\n",
    "        \n",
    "    print(\"Overall Accuracy:\", score/word_ids.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.9002885241832904\n"
     ]
    }
   ],
   "source": [
    "classifier_score_top_5(test_x_word_ids, test_y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.8147536057692307\n"
     ]
    }
   ],
   "source": [
    "classifier_score_top_5(LR_x_word_ids, LR_y, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
