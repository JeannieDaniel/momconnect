{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with 1024 hidden units\n",
    "\n",
    "Author: Jeanne Elizabeth Daniel\n",
    "\n",
    "November 2019\n",
    "\n",
    "We employ the humble long short-term memory network with 512 hidden units to model the input sequence of words. The LSTM was introduced by Hochreiter and Schmidhuber (1997) to address the shortcomings of the original recurrent neural network (RNN). The LSTM's architecture is similar to that of the RNN, but with more parameters, such as gating units and an internal state unit that explicitly address the long-term dependency problem of the RNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "#sys.path.append(os.path.join(\\\"..\\\")) # path to source relative to current directory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess_data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, TimeDistributed, Input, Flatten, AdditiveAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset_7B', delimiter = ';', engine = 'python')\n",
    "data_text = data.loc[data['set'] == 'Train'][['helpdesk_question']]\n",
    "number_of_classes = data.loc[data['set'] == 'Train']['helpdesk_reply'].value_counts().shape[0]\n",
    "data = data[['helpdesk_question', 'helpdesk_reply', 'set', 'low_resource']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = pd.DataFrame(data.loc[data['set'] == 'Train']['helpdesk_reply'].value_counts()).reset_index()\n",
    "responses['reply'] = responses['index']\n",
    "responses['index'] = responses.index\n",
    "responses = dict(responses.set_index('reply')['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = preprocess_data.create_dictionary(data_text, 1, 0.25, 95000) #our entire vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data.loc[data['set'] == 'Train']\n",
    "df_train = df_train.reset_index()[['helpdesk_question', 'helpdesk_reply']]\n",
    "\n",
    "df_valid = data.loc[data['set'] == 'Valid']\n",
    "df_valid = df_valid.reset_index()[['helpdesk_question', 'helpdesk_reply']]\n",
    "\n",
    "df_test = data.loc[data['set'] == 'Test']\n",
    "df_test = df_test.reset_index()[['helpdesk_question', 'helpdesk_reply']]\n",
    "\n",
    "df_LR = data.loc[(data['set'] == 'Test') & (data['low_resource'] == 'True') ]\n",
    "df_LR = df_LR.reset_index()[['helpdesk_question', 'helpdesk_reply']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96412, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57545"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 30\n",
    "min_token_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id, id_to_word = preprocess_data.create_lookup_tables(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming the input sentence into a sequence of word IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96412, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x_word_ids = []\n",
    "for question in df_train['helpdesk_question'].apply(preprocess_data.preprocess_question, \n",
    "                                                    args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    train_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "train_x_word_ids = np.stack(train_x_word_ids)\n",
    "print(train_x_word_ids.shape)\n",
    "    \n",
    "val_x_word_ids = []\n",
    "for question in data['helpdesk_question'].loc[data['set'] == 'Valid'].apply(preprocess_data.preprocess_question, \n",
    "                                                                          args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    val_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "val_x_word_ids = np.stack(val_x_word_ids)\n",
    "\n",
    "test_x_word_ids = []\n",
    "for question in data['helpdesk_question'].loc[data['set'] == 'Test'].apply(preprocess_data.preprocess_question, \n",
    "                                                                          args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    test_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "    \n",
    "test_x_word_ids = np.stack(test_x_word_ids)\n",
    "\n",
    "LR_x_word_ids = []\n",
    "for question in data['helpdesk_question'].loc[(data['set'] == 'Test') & \n",
    "                                              (data['low_resource'] == 'True')].apply(preprocess_data.preprocess_question, \n",
    "                                                                          args = [unique_words, min_token_length]):\n",
    "    word_ids = preprocess_data.transform_sequence_to_word_ids(question, word_to_id)\n",
    "    LR_x_word_ids.append(np.array(word_ids, dtype = float))\n",
    "LR_x_word_ids = np.stack(LR_x_word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(reply, all_responses):\n",
    "    \n",
    "    \"\"\" Constructs a one-hot vector for replies\n",
    "    \n",
    "    Args:\n",
    "        reply: query item \n",
    "        all_responses: dict containing all the template responses with their corresponding IDs\n",
    "    \n",
    "    Return:\n",
    "        a one-hot vector where the corresponding ID of the reply is the one-hot index\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Y = np.zeros(len(all_responses), dtype = int)\n",
    "    Y[all_responses[reply]] += 1\n",
    "    return Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.array(list(df_train['helpdesk_reply'].apply(get_dummies, args = [responses])))\n",
    "valid_y = np.array(list(df_valid['helpdesk_reply'].apply(get_dummies, args = [responses])))\n",
    "test_y  = np.array(list(df_test['helpdesk_reply'].apply(get_dummies,  args = [responses])))\n",
    "LR_y    = np.array(list(df_LR['helpdesk_reply'].apply(get_dummies,         args = [responses])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_word_ids = train_x_word_ids.reshape(train_x_word_ids.shape[:-1])\n",
    "val_x_word_ids   = val_x_word_ids.reshape(val_x_word_ids.shape[:-1])\n",
    "test_x_word_ids  = test_x_word_ids.reshape(test_x_word_ids.shape[:-1])\n",
    "LR_x_word_ids    = LR_x_word_ids.reshape(LR_x_word_ids.shape[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla LSTMs using the final hidden state as sentence embedding. \n",
    "\n",
    "The network consists of an embedding layer, followed by a dropout layer, followed by an LSTM network. The final hidden LSTM state is fed to a dense classification layer.\n",
    "We train with a dropout rate of 0.25 and batch size of 32. During training we use early stopping and Adadelta as our optimization algorithm. This network has an embedding of size 300 and 1024 hidden units in the LSTM network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_lstm(max_features, output_dim=100, input_length = 30, lstm_units = 128):\n",
    "    \n",
    "    \"\"\" Constructs an LSTM classifier with an embedding and dropout layer preceding the LSTM network. \n",
    "    \n",
    "    Args:\n",
    "        max_features: size of vocabulary\n",
    "        output_dim: dimension of embedding vector\n",
    "        input_length: length of input sequence\n",
    "        lstm_units: number of hidden units in LSTM\n",
    "    \n",
    "    Returns:\n",
    "        An LSTM model\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, output_dim=output_dim, input_length = input_length, mask_zero=True ))\n",
    "    model.add(Dropout(rate = 0.25))\n",
    "    model.add(LSTM(lstm_units, activation = 'tanh', return_sequences = False, input_shape = (30,), \n",
    "               dropout = 0.25, recurrent_dropout = 0.5))\n",
    "    model.add(Dense(89, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_features = len(unique_words) + 1\n",
    "\n",
    "model = vanilla_lstm(max_features, output_dim=300, input_length=30, lstm_units = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 30, 300)           17263500  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1024)              5427200   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 89)                91225     \n",
      "=================================================================\n",
      "Total params: 22,781,925\n",
      "Trainable params: 22,781,925\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', verbose=1, restore_best_weights=True, patience=20)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96412 samples, validate on 31955 samples\n",
      "Epoch 1/500\n",
      "96412/96412 [==============================] - 246s 3ms/sample - loss: 2.6001 - accuracy: 0.4086 - val_loss: 2.1145 - val_accuracy: 0.4663\n",
      "Epoch 2/500\n",
      "96412/96412 [==============================] - 250s 3ms/sample - loss: 1.9677 - accuracy: 0.4954 - val_loss: 1.8152 - val_accuracy: 0.5189\n",
      "Epoch 3/500\n",
      "96412/96412 [==============================] - 252s 3ms/sample - loss: 1.7303 - accuracy: 0.5329 - val_loss: 1.6786 - val_accuracy: 0.5445\n",
      "Epoch 4/500\n",
      "96412/96412 [==============================] - 254s 3ms/sample - loss: 1.5709 - accuracy: 0.5619 - val_loss: 1.5975 - val_accuracy: 0.5594\n",
      "Epoch 5/500\n",
      "96412/96412 [==============================] - 253s 3ms/sample - loss: 1.4559 - accuracy: 0.5849 - val_loss: 1.5342 - val_accuracy: 0.5704\n",
      "Epoch 6/500\n",
      "96412/96412 [==============================] - 253s 3ms/sample - loss: 1.3584 - accuracy: 0.6053 - val_loss: 1.4974 - val_accuracy: 0.5782\n",
      "Epoch 7/500\n",
      "96412/96412 [==============================] - 253s 3ms/sample - loss: 1.2807 - accuracy: 0.6250 - val_loss: 1.4727 - val_accuracy: 0.5824\n",
      "Epoch 8/500\n",
      "96412/96412 [==============================] - 254s 3ms/sample - loss: 1.2079 - accuracy: 0.6413 - val_loss: 1.4750 - val_accuracy: 0.5890\n",
      "Epoch 9/500\n",
      "96412/96412 [==============================] - 254s 3ms/sample - loss: 1.1367 - accuracy: 0.6608 - val_loss: 1.4604 - val_accuracy: 0.5929\n",
      "Epoch 10/500\n",
      "96412/96412 [==============================] - 253s 3ms/sample - loss: 1.0750 - accuracy: 0.6762 - val_loss: 1.4652 - val_accuracy: 0.5977\n",
      "Epoch 11/500\n",
      "96412/96412 [==============================] - 252s 3ms/sample - loss: 1.0173 - accuracy: 0.6927 - val_loss: 1.4720 - val_accuracy: 0.5991\n",
      "Epoch 12/500\n",
      "96412/96412 [==============================] - 253s 3ms/sample - loss: 0.9616 - accuracy: 0.7110 - val_loss: 1.4939 - val_accuracy: 0.5952\n",
      "Epoch 13/500\n",
      "96412/96412 [==============================] - 253s 3ms/sample - loss: 0.9145 - accuracy: 0.7232 - val_loss: 1.4993 - val_accuracy: 0.6004\n",
      "Epoch 14/500\n",
      "96412/96412 [==============================] - 253s 3ms/sample - loss: 0.8634 - accuracy: 0.7362 - val_loss: 1.5353 - val_accuracy: 0.5943\n",
      "Epoch 15/500\n",
      "96412/96412 [==============================] - 252s 3ms/sample - loss: 0.8190 - accuracy: 0.7505 - val_loss: 1.5347 - val_accuracy: 0.5976\n",
      "Epoch 16/500\n",
      "96412/96412 [==============================] - 251s 3ms/sample - loss: 0.7817 - accuracy: 0.7591 - val_loss: 1.5601 - val_accuracy: 0.5933\n",
      "Epoch 17/500\n",
      "96412/96412 [==============================] - 250s 3ms/sample - loss: 0.7472 - accuracy: 0.7709 - val_loss: 1.5747 - val_accuracy: 0.6009\n",
      "Epoch 18/500\n",
      "96412/96412 [==============================] - 251s 3ms/sample - loss: 0.7125 - accuracy: 0.7794 - val_loss: 1.6190 - val_accuracy: 0.6005\n",
      "Epoch 19/500\n",
      "96412/96412 [==============================] - 251s 3ms/sample - loss: 0.6824 - accuracy: 0.7891 - val_loss: 1.6293 - val_accuracy: 0.6003\n",
      "Epoch 20/500\n",
      "96412/96412 [==============================] - 250s 3ms/sample - loss: 0.6516 - accuracy: 0.7976 - val_loss: 1.6606 - val_accuracy: 0.5997\n",
      "Epoch 21/500\n",
      "96412/96412 [==============================] - 250s 3ms/sample - loss: 0.6246 - accuracy: 0.8069 - val_loss: 1.6658 - val_accuracy: 0.6024\n",
      "Epoch 22/500\n",
      "96412/96412 [==============================] - 250s 3ms/sample - loss: 0.6034 - accuracy: 0.8121 - val_loss: 1.6998 - val_accuracy: 0.5972\n",
      "Epoch 23/500\n",
      "96412/96412 [==============================] - 250s 3ms/sample - loss: 0.5783 - accuracy: 0.8198 - val_loss: 1.7096 - val_accuracy: 0.5994\n",
      "Epoch 24/500\n",
      "96412/96412 [==============================] - 251s 3ms/sample - loss: 0.5555 - accuracy: 0.8272 - val_loss: 1.7472 - val_accuracy: 0.5988\n",
      "Epoch 25/500\n",
      "96412/96412 [==============================] - 250s 3ms/sample - loss: 0.5360 - accuracy: 0.8327 - val_loss: 1.7520 - val_accuracy: 0.5970\n",
      "Epoch 26/500\n",
      "96412/96412 [==============================] - 248s 3ms/sample - loss: 0.5149 - accuracy: 0.8380 - val_loss: 1.7763 - val_accuracy: 0.6028\n",
      "Epoch 27/500\n",
      "96412/96412 [==============================] - 250s 3ms/sample - loss: 0.4976 - accuracy: 0.8449 - val_loss: 1.8175 - val_accuracy: 0.6003\n",
      "Epoch 28/500\n",
      "96412/96412 [==============================] - 250s 3ms/sample - loss: 0.4794 - accuracy: 0.8482 - val_loss: 1.8335 - val_accuracy: 0.5992\n",
      "Epoch 29/500\n",
      "96412/96412 [==============================] - 250s 3ms/sample - loss: 0.4666 - accuracy: 0.8509 - val_loss: 1.8568 - val_accuracy: 0.5993\n",
      "Epoch 30/500\n",
      "96412/96412 [==============================] - 250s 3ms/sample - loss: 0.4488 - accuracy: 0.8577 - val_loss: 1.8878 - val_accuracy: 0.5982\n",
      "Epoch 31/500\n",
      "96412/96412 [==============================] - 250s 3ms/sample - loss: 0.4314 - accuracy: 0.8642 - val_loss: 1.9274 - val_accuracy: 0.5987\n",
      "Epoch 32/500\n",
      "96412/96412 [==============================] - 249s 3ms/sample - loss: 0.4182 - accuracy: 0.8670 - val_loss: 1.9368 - val_accuracy: 0.6024\n",
      "Epoch 33/500\n",
      "96412/96412 [==============================] - 213s 2ms/sample - loss: 0.4066 - accuracy: 0.8714 - val_loss: 1.9374 - val_accuracy: 0.6013\n",
      "Epoch 34/500\n",
      "96412/96412 [==============================] - 209s 2ms/sample - loss: 0.3941 - accuracy: 0.8742 - val_loss: 1.9468 - val_accuracy: 0.6001\n",
      "Epoch 35/500\n",
      "96412/96412 [==============================] - 208s 2ms/sample - loss: 0.3815 - accuracy: 0.8778 - val_loss: 1.9912 - val_accuracy: 0.5999\n",
      "Epoch 36/500\n",
      "96412/96412 [==============================] - 210s 2ms/sample - loss: 0.3667 - accuracy: 0.8829 - val_loss: 2.0249 - val_accuracy: 0.5972\n",
      "Epoch 37/500\n",
      "96412/96412 [==============================] - 210s 2ms/sample - loss: 0.3571 - accuracy: 0.8858 - val_loss: 2.0461 - val_accuracy: 0.6002\n",
      "Epoch 38/500\n",
      "96412/96412 [==============================] - 210s 2ms/sample - loss: 0.3489 - accuracy: 0.8882 - val_loss: 2.0453 - val_accuracy: 0.5947\n",
      "Epoch 39/500\n",
      "96412/96412 [==============================] - 200s 2ms/sample - loss: 0.3390 - accuracy: 0.8923 - val_loss: 2.0858 - val_accuracy: 0.5998\n",
      "Epoch 40/500\n",
      "96412/96412 [==============================] - 191s 2ms/sample - loss: 0.3281 - accuracy: 0.8963 - val_loss: 2.0991 - val_accuracy: 0.5973\n",
      "Epoch 41/500\n",
      "96412/96412 [==============================] - 190s 2ms/sample - loss: 0.3228 - accuracy: 0.8966 - val_loss: 2.1175 - val_accuracy: 0.5989\n",
      "Epoch 42/500\n",
      "96412/96412 [==============================] - 191s 2ms/sample - loss: 0.3132 - accuracy: 0.9002 - val_loss: 2.1378 - val_accuracy: 0.5985\n",
      "Epoch 43/500\n",
      "96412/96412 [==============================] - 192s 2ms/sample - loss: 0.3087 - accuracy: 0.9012 - val_loss: 2.1494 - val_accuracy: 0.5982\n",
      "Epoch 44/500\n",
      "96412/96412 [==============================] - 192s 2ms/sample - loss: 0.3037 - accuracy: 0.9037 - val_loss: 2.1677 - val_accuracy: 0.6007\n",
      "Epoch 45/500\n",
      "96412/96412 [==============================] - 192s 2ms/sample - loss: 0.2938 - accuracy: 0.9065 - val_loss: 2.1850 - val_accuracy: 0.6003\n",
      "Epoch 46/500\n",
      "96352/96412 [============================>.] - ETA: 0s - loss: 0.2878 - accuracy: 0.9093Restoring model weights from the end of the best epoch.\n",
      "96412/96412 [==============================] - 192s 2ms/sample - loss: 0.2878 - accuracy: 0.9093 - val_loss: 2.2254 - val_accuracy: 0.5994\n",
      "Epoch 00046: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb68cc5bd30>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x_word_ids, train_y,\n",
    "          batch_size=32,\n",
    "          epochs=500,\n",
    "          callbacks=[es],\n",
    "          validation_data=[val_x_word_ids, valid_y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.605001\n",
       "False    0.394999\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict_classes(test_x_word_ids)\n",
    "pd.Series(np.argmax(test_y, axis = 1) == preds).value_counts()/test_y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.51893\n",
       "False    0.48107\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict_classes(LR_x_word_ids)\n",
    "pd.Series(np.argmax(LR_y, axis = 1) == preds).value_counts()/LR_y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[0].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-5 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_score_top_5(word_ids, y_true, model):\n",
    "    \n",
    "    \"\"\" Computes top-5 classification accuracy for model.\n",
    "    \n",
    "    Args:\n",
    "        word_ids: matrix where each row is \n",
    "        y_true:\n",
    "        model:\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    score = 0\n",
    "    probs = model.predict(word_ids)\n",
    "    for i in range(word_ids.shape[0]):\n",
    "        if y_true[i].argmax() in np.argsort(probs[i])[-5:]:\n",
    "            score += 1\n",
    "        \n",
    "    print(\"Overall Accuracy:\", score/word_ids.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.8895231594949276\n"
     ]
    }
   ],
   "source": [
    "classifier_score_top_5(test_x_word_ids, test_y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.7931189903846154\n"
     ]
    }
   ],
   "source": [
    "classifier_score_top_5(LR_x_word_ids, LR_y, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
